%!TEX encoding = UTF-8 Unicode
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[hmargin=1in,vmargin=1in]{geometry}

\usepackage[dvipsnames,usenames]{xcolor}

\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage{euscript}
\usepackage{mathpazo}
\usepackage[scaled=.90]{berasans,beramono}

%\usepackage{epsfig}
%\usepackage{floatflt}
\usepackage{graphicx}

\usepackage{microtype}
\usepackage{subcaption}
\usepackage{xspace}
\usepackage[shortlabels, inline]{enumitem}

\usepackage{latexsym,amsmath,amssymb,amsthm}
\usepackage{algpseudocode,algorithm,algorithmicx}
\usepackage{mathtools} % for \coloneqq

\usepackage[title]{appendix}

\usepackage{ifpdf}

%\graphicspath{{fig/}}

%\DeclareGraphicsExtensions{.pdf}

%\ifpdf
%\else
%   \DeclareGraphicsExtensions{.eps}
%\fi

\def\etal{\textsl{et~al.}}
\def\polylog{\mathop{\mathrm{polylog}}}
\def\eps{\varepsilon}
\def\softO{\widetilde{O}}
\def\bd{{\partial}}
\def\reals{\mathbb{R}}
\def\ints{\mathbb{N}}
\def\flr#1{{\lfloor #1\rfloor}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\def\tsupply{\lambda}
\def\fsupply{\phi}

\def\Refine{\textsc{Refine}}
\def\Update{\textsc{Update}}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{observation}{Observation}
\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}

\newcommand{\lemlab}[1]{\label{lem:#1}}
\newcommand{\figlab}[1]{\label{fig:#1}}
\newcommand{\theolab}[1]{\label{theo:#1}}
\newcommand{\corlab}[1]{\label{cor:#1}}
\def\lemref#1{Lemma~\ref{lemma:#1}}
\def\theoref#1{Theorem~\ref{theo:#1}}
\def\corref#1{Corollary~\ref{cor:#1}}
\def\figref#1{Figure~\ref{fig:#1}} \def\secref#1{Section~\ref{sec:#1}}

\def\parent{\operatorname{par}}
\def\cost{\operatorname{cost}}


\makeatletter
\long\def\@makecaption#1#2{
    \vskip 10pt
    \setbox\@tempboxa\hbox{{\footnotesize {\bf #1.} #2}}
    \ifdim \wd\@tempboxa >\hsize         % IF longer than one line:
        {\footnotesize {\bf #1.} #2\par}% THEN set as ordinary paragraph.
      \else                              %   ELSE  center.
        \hbox to\hsize{\hfil\box\@tempboxa\hfil}
    \fi}
%\dbltextfloatsep 18pt plus 2pt minus 4pt   % was 20pt plus 2pt minus 4pt
%\textfloatsep 18pt plus 2pt minus 4pt      % was 20pt plus 2pt minus 4pt
\makeatother

% ----------------------------------------------------------------------
%  Notes to myself.  The margin flags are broken, thanks to an
%  incompatibility with the geometry package.
% ----------------------------------------------------------------------
\def\n@te#1{\textsf{\boldmath \textbf{$\langle\!\langle$#1$\rangle\!\rangle$}}\leavevmode}
\def\note#1{\textcolor{red}{\n@te{#1}}}


%----------------------------------------------------------------------
% 'cramped' list style, stolen from Jeff Vitter.  Doesn't always work.
%----------------------------------------------------------------------
\def\cramped
  {\parskip\@outerparskip\@topsep\parskip\@topsepadd2pt\itemsep0pt
}


%% METAFILE
\title{ Geometric Partial Matching and Unbalanced Transportation %
\date{\today} % replace with date?
\author{
Pankaj K.\ Agarwal
\and
Allen Xiao
}
}


\begin{document}

\maketitle

\section{Introduction}

Consider the problem of finding a minimum-cost bichromatic matching between
a set of red points $A$ and a set of blue points $B$ lying in the plane,
where the cost of a matching edge $(a, b)$ is the Euclidean distance
$\|a - b\|$;
in other words, the minimum-cost bipartite matching problem on the Euclidean
complete graph $G = (A \cup B, A \times B)$.
Let $r$ be the number of vertices in $A$, and $n$ be the number of vertices in $B$.
Without loss of generality assume that $r \leq n$.
We consider the problem of \emph{partial matching}, where the task is to
find the minimum-cost matching of size $k$ (which by definition is at most $r$).
When $k = r = n$, we say the matching instance is \emph{balanced}
and call the problem \emph{perfect matching} or the \emph{assignment problem}.
When $k = r < n$ ($A$ and $B$ have different sizes, but the matching is
maximal), we say the matching instance is \emph{unblanced}.
\note{Don't mix up the definition of \emph{balanced} and \emph{perfect}; the former is between $r$ and $n$, where the latter is between $k$ and $r$.}
Partial matching generalizes both perfect matching and unbalanced matching.
We will refer to the geometric problem as \emph{geometric partial matching}.
\text{Maybe bad nameing; there is nothing geometric about this name.}

% \begin{TODO}
% Previous work
% \begin{itemize}\itemsep=0pt
% 	\item on matching
% 	\item on geometric matching
% 	\item on unbalanced/partial problems (GHKT, the push-relabel one, the tech report)
% \end{itemize}
% \noindent\textcolor{blue}{[Hsien: State your TODO list explicitly in the pdf file so that it's easier to read.  Make everything that you are planning to do, and put priorities on them.]}
% \end{TODO}


\subsection{Contributions}

In this paper, we present two algorithms for geometric partial matching
that are based on fitting nearest-neighbor (NN) and geometric closest pair
(BCP) oracles into primal-dual algorithms for non-geometric bipartite matching
and minimum-cost flow.
This pattern is not new, see for example \note{TODO}.
Unlike these previous works, we focus on obtaining running time dependencies on
$k$ or $r$ instead of $n$, that is, faster for inputs with small $r$ or $k$.
We begin in Section~\ref{section:prelim} by introducing notation for matching
and minimum-cost flow.

% O((n + k^2)\polylog n)

First in Section~\ref{section:hung}, we show that the Hungarian algorithm~\cite{Kuhn55}
combined with a BCP oracle solves geometric partial matching exactly in time
$O((n + k^2)\polylog n)$.
Mainly, we show that we can separate the $O(n\polylog n)$ preprocessing time
for building the BCP data structure from the augmenting paths' search time,
and update duals in a lazy fashion such that the number of dual updates per
augmenting path is $O(k)$.

\begin{theorem}
\label{theorem:hung}
Let $A$ and $B$ be two point sets in the plane with $|A| = r$ and $|B| = n$ satisfying $r \le n$, and let $k$ be a
parameter.  A minimum-cost geometric partial matching of size $k$
can be computed between $A$ and $B$ in $O((n + k^2)\polylog n)$ time.
\end{theorem}

% O((n + k\sqrt{k})\polylog(n)\log(n/\eps))

Next in Section~\ref{section:goldberg}, we apply a similar technique to the unit-capacity min-cost circulation
algorithm of Goldberg, Hed, Kaplan, and Tarjan~\cite{GHKT17}.
The resulting algorithm finds a $(1 + \eps)$-approximation to the optimal
geometric partial matching in $O((n + k\sqrt{k})\polylog n \log(n/\eps))$
time.

\begin{theorem}
\label{theorem:gmcm}
Let $A$ and $B$ be two point sets in the plane with $|A| = r$ and $|B| = n$ satisfying $r \le n$, and let $k$ be a
parameter.
A $(1+\eps)$ geometric partial matching of size $k$
can be computed between $A$ and $B$ in
$O((n + k\sqrt{k})\polylog n \log(n/\eps))$ time.
\end{theorem}

% add the ~O(rn^{3/2}) version

Our third algorithm solves the transportation problem in the unbalanced
setting.
%with $|A| = r$ and $|B| = n$.
This time, we use the strongly polynomial uncapacitated min-cost flow algorithm
by Orlin~\cite{xxx} \note{Cite}.
The result is an $O(n^{3/2} r \polylog n)$ time algorithm for unbalanced
transportation.
This improves over the $O(n^2 \polylog(n))$ time algorithm of %TODO cite
when $r = o(\sqrt{n})$.

\begin{theorem}
\label{theorem:orlin}
Let $A$ and $B$ be two point sets in the plane with $|A| = r$ and $|B| = n$ satisfying $r \le n$, with
supplies and demands given by the function $\tsupply(\cdot)$ \note{from $A\cup B$ to $\mathbb{Z}$?} such that
$\sum_{a \in A} \tsupply(a) = \sum_{b \in B} \tsupply(b)$.
An optimal transportation map can be computed in $O(n^{3/2}r\polylog n)$ time.
\end{theorem}

%TODO STILL IN PROGRESS, WE DON'T HAVE A SOLUTION YET. REMOVE IF FAILS.

%Finally, we show that an algorithm by Orlin~\cite{} for uncapacitated min-cost
%flow can be modified to give an $O(nr\polylog(n))$ time algorithm for the
%unbalanced transportation problem.
%Unlike matching, vertices may be ``matched'' (transporting) to more than one
%other vertex.
%As a result, it seems possible that the search procedure reaches vertices which
%do not contribute to a new augmenting path or towards finding unreached $B$
%vertices, forcing the search to backtrack.
%Avoiding the backtracking is the main challenge for this algorithm.
%% how?

By nature of the BCP/NN oracles we use, our results generalize to any $L_p$ distances. \note{Mention Euclidean distance earlier.}


\section{Preliminaries}
\label{section:prelim}

\subsection{Matching}

Let $G$ be a bipartite graph between vertex sets $A$ and $B$ and edge set $E$,
with costs $c(v, w)$ for each edge $e$ in $E$.
We use $C = \max_{e \in E} c(e)$, \note{you might want to use $\coloneqq$ instead of $=$ for definition?} and assume that the problem is scaled such
that $\min_{e \in E} c(e) = 1$.
A \emph{matching} $M \subseteq E$ is a set of edges where no two edges share an
endpoint.
We use $V(M)$ to denote the vertices matched by $M$.
The \emph{size} of a matching is the number of edges in the set, and the \emph{cost} of a
matching is the sum of costs of its edges.
The \emph{minimum-cost partial matching problem (MPM)} asks to find a size-$k$
matching $M^*$ of minimum cost.

\subsection{Minimum-cost flow}

\note{Collect definitions into paragraphs.}

\paragraph{Network.}
For minimum-cost flow, let $G_0 = (V, E_0)$ be a directed graph with
nonnegative arc capacities $u(v, w)$ and costs $c(v, w)$ for each arc
$(v, w) \in E_0$.
We say $G_0$ is \emph{unit-capacity} if $u(v, w) = 1$ holds for all arc $(v, w)$.
Let $\fsupply: V \to \ints_{\geq 0}$ be a supply-demand function on $V$, satisfying $\sum_{v \in V} \fsupply(v) = 0$.
The positive values of $\fsupply(v)$ are referred to as \emph{supply}, and the negative values of $\fsupply(v)$ as \emph{demand}.

We augment $G_0$ to make it \emph{symmetric}
%for every arc $(v, w) \in E_0$ its reverse $(w, v)$ is also an arc;
and the costs
\emph{antisymmetric}
%$c(v, w) = -c(w, v)$).
by creating an arc $(w, v)$ for each $(v, w) \in E_0$ and define $u(w, v) = 0$ and $c(w, v) = -c(v, w)$.
Denote this set of new \emph{reverse arcs} by $E^R$.
\note{How do you feel about using darts and arcs to describe the distinction?}
From here forward, we work with the symmetric multigraph
$G = (V, E = E_0 \cup E^R)$. \note{Oh man.  This is a mouthful, use English.}
A \emph{network} $(G, c, u, \fsupply)$ is a graph $G$ argmented with arc costs, capacities, and a supply-demand function on vertices of $G$.

\paragraph{Pseudoflows.}
A \emph{pseudoflow} $f$ is an antisymmetric function on arcs \note{define codomain; integers?}
satisfying $f(v, w) \leq u(v, w)$ for all arcs $(v, w)$.
We say that $f$ \emph{saturates} an arc $e$ if $f(v, w) = u(v, w)$.
All our algorithms will handle integer-valued pseudoflows, so in the
unit-capacity setting an arc is either saturated or has zero flow.
Given a pseudoflow $f$, we define the \emph{imbalance} of a vertex to be
\[
e_f(v) \coloneqq \fsupply(v) + \sum_{(w, v) \in E}{f(w, v)} - \sum_{(v, w) \in E}{f(v, w)}.
\]
We call positive imbalance \emph{excess} and negative imbalance \emph{deficit}; and
vertices with positive and negative imbalance \emph{excess vertices} and \emph{deficit vertices}, respectively.
A vertex is \emph{balanced} if it has zero imbalance.
If all vertices are balanced, the pseudoflow is a \emph{circulation}.
The cost of a pseudoflow is
\[
\cost(f) \coloneqq \sum_{(v, w) \in E} c(v, w) \cdot f(v, w).
\]
The \emph{minimum-cost flow problem (MCF)} asks to find the circulation $f^*$ of
minimum cost.

\paragraph{Residual network.}
For each arc $(v, w)$, the \emph{residual capacity} with respect to
pseudoflow $f$ is defined to be $u_f(v, w) \coloneqq u(v, w) - f(v, w)$.
The set of \emph{residual edges} \note{arcs?} is defined as
\[
E_f \coloneqq \{(v, w) \in E \mid u_f(v, w) > 0\}.
\]
We call $G_f = (V, E_f)$ the \emph{residual graph} with respect to pseudoflow $f$.
A pseudoflow $f'$ in $G_f$ can be ``added'' or ``augmented'' to $f$ to produce
a new pseudoflow (that is, the arc-wise addition $f + f'$ is a valid pseudoflow
in $G$).
A pseudoflow $f'$ in $G_f$ is an \emph{improving flow} if
\begin{enumerate}[(1)]\itemsep=0pt
\item
$0 \leq e_{f'}(v) \leq e_f(v)$ for all excess vertices $v$,
\item
$0 \leq -e_{f'}(v) \leq -e_f(v)$ for all deficit vertices $v$, and
%\item
% if $e_f(v) = 0$ then $e_{f'}(v) = 0$, \note{this follows from (1) or (2)} and
\item $\sum_{v \in V} |e_{f'}(v)| < \sum_{v \in V} |e_f(v)|$ holds. \note{this follows from (1) and (2) too?}
\end{enumerate}
If improving flow $f'$ is on a simple path (from an excess vertex to a deficit
vertex), we call it an \emph{augmenting-path flow} \note{path flow for short? only used twice throughout the paper} and its underlying support path \note{support undefined} an
\emph{augmenting path}.
If $f'$ saturates at least one residual arc in every augmenting path in $G_f$,
we call $f'$ a \emph{blocking flow}.
In other words, for blocking flow $f'$, there is no augmenting-path flow
$f''$ in $G_f$ for which $f + (f' + f'')$ is a feasible pseudoflow in $G$.

\subsection{Primal-dual augmentation algorithms}

The Hungarian algorithm begins with an empty matching and gradually increases its size to $k$ using \emph{alternating augmenting paths}.
Given a non-maximal matching $M$, an alternating augmenting path $P$ is a path
between an unmatched vertex $a \in A$ and unmatched $b \in B$.
\note{What is $A$ and $B$? Remind the readers about the bipartite graph again.}
Then, $M' = M \oplus P$ is a matching of size 1 greater.
\note{$\oplus$ undefined.  Personally I believe it's easier to define in words; using notation is fine too.}
By restricting alternating augmenting paths to edges \note{when do you use edges and when do you use arcs?}
which satisfy a certain
cost condition (admissibility, defined momentarily) \note{define it or don't say it}, one can prove that each
intermediate matching of size $j \leq k$ is of minimum-cost among matchings of size $j$.

There is a similar augmentation procedure for flows, which sends improving
flows (e.g. augmenting-path flows) \note{no reason to give out details that does not help with sketch of ideas} to gradually reduce the imbalance in a
pseudoflow to 0, making it a circulation. \note{imbalance of a pseudoflow is undefined; you only define it on the vertices.}
By restricting augmentations to residual arcs satisfying a certain cost
condition (admissibility), one can prove that the resulting circulation is
minimum cost.

\note{The above paragraph might be clearer if you put it after the definition of admissibility; because you can actually provide a formal proof.  Sketch of ideas are not that useful because for experts they don't need to read it, for beginners they won't understand without former definitions.}

\paragraph{LP-duality and admissability.}
Formally, the
\emph{potentials} $\pi(v)$ are the variables of the linear program dual to \note{which primal problem? State the correspodning linear problems explicitly}.
The \emph{reduced cost} of an arc $(v, w)$ in $E_f$ with respect to $\pi$ is
\[
c_\pi(v, w) := c(v, w) - \pi(v) + \pi(w).
\]
\note{Mention that reduced costs are still antisymmetric.}
The \emph{dual feasibility constraint} is that $c_\pi(v, w) \geq 0$ holds for all
residual arcs; potentials which satisfy this constraint are said to be \emph{feasible}.
The linear programming \emph{optimality conditions} state that, for an optimal
circulation $f^*$, there are feasible potentials $\pi^*$ which satisfy
$c_\pi(v, w) = 0$ \note{$\pi^*$?} on all arcs with $f^*(v, w) > 0$.
We can similarly define potentials and reduced costs for matchings, using
$c_\pi(a, b) = c(a, b) - \pi(a) + \pi(b)$ for $(a, b) \in A \times B$.

Suppose we relax the dual feasibility constraint to allow for a violation of
$\eps > 0$.
We say that a pseudoflow $f$ is \emph{$\eps$-optimal} \note{with respect to $\pi$} if
$c_\pi(v, w) \geq -\eps$ for all arcs $(v, w)$ in $E_f$ with $u_f(v, w) > 0$.
Note that 0-optimality coincides with the optimality conditions. \note{Careful here.  Technically it's dual feasibility.}
We say that a residual arc $(v ,w)$ satisfying $c_\pi(v, w) \leq 0$ is \emph{admissible}.
We say that an improving flow $f'$ is \emph{admissible} if $f'(v, w) > 0$
only on admissible arcs $(v, w)$.
%
For matchings, we say that matching $M$ is $\eps$-optimal if $c_\pi(a, b) \leq \eps$ for
$(a, b) \in M$ and $c_\pi(a, b) \geq -\eps$ $(a, b) \in E \setminus M$.
Matching edges (resp.\ nonmatching edges) are \emph{admissible} if $c_\pi(a, b) \geq 0$ (resp.\ $c_\pi(a, b) \leq 0$); and an alternating augmenting path is \emph{admissible}
if all its edges are.
For both matching and flows, 0-optimal $f$ implies the admissibility condition
is with equality, instead ($c_\pi(v, w) = 0$).

\note{I got the sense that it might be helpful to define admissibility at the start of the flow section and the matching section separately.}

%Now, we can concretely state how admissible augmentations lead to a correct algorithm for $\eps > 0$.
\begin{lemma}
	Let $f$ be an $\eps$-optimal pseudoflow in $G$ and let $f'$ be an
	admissible improving flow in $G_f$.
	Then $f + f'$ is also $\eps$-optimal.
\end{lemma}
\begin{proof}
	Augmentation by $f'$ will not change the potentials, but may introduce
	new arcs with $u_{f+f'}(v, w) > 0$.
	We will verify that these arcs satisfy the $\eps$-optimality condition.
	Such an arc $(v, w)$ must have $u(v, w) = f(v, w) > (f+f')(v, w)$,
	implying $f'(w, v) > 0$.
\note{I don't understand.  Never write a sentense that requires multiple steps to decode. I think what you meant is $u_f = 0$ thus $u=f$, and $u_{f+f'} > 0$ thus $u-(f+f') > 0$; finally $f'(v,w) > 0$ thus $f'(w,v) < 0$.}
	By assumption that $f'$ is admissible, $(w, v)$ was an admissible arc, thus
	$c_\pi(w, v) \leq 0$, implying $c_\pi(v, w) \geq 0$.
	Thus, all such arcs have $c_\pi(v, w) \geq 0 \geq -\eps$, and $f + f'$
	is $\eps$-optimal.
\end{proof}

With a similar argument, we could prove the same for matchings. \note{Proof it or cite it, at least in full version.}
Finally, we show that $\eps$-optimality is sufficient to certify that a
circulation is an approximate MCF solution, when the underlying graph is
of unit-capacity.

\begin{lemma}
\label{lemma:mcf_cost}
	Let $G$ be a unit-capacity graph with $n$ vertices and $m$ arcs,
	let $f$ be an $\eps$-optimal circulation in $G$, and let $f^*$ be an optimal circulation for $G$.
	Then, $\cost(f) \leq \cost(f^*) + m\eps$.
\end{lemma}
\begin{proof}
	By the flow decomposition theorem \note{cite?}, there is a residual pseudoflow
	$f'$ such that $f + f' = f^*$, and $f'$ can be decomposed into a set of
	unit flows on edge-disjoint cycles.
	The number of edges used by these cycles is at most $m$.
	The cost of a residual cycle is equal to its reduced cost, since the
	potentials telescope.
	Thus, $\cost(f') \geq m(-\eps)$ \note{why is $f'$ $\eps$-optimal?}, and therefore
	$\cost(f) \leq \cost(f^*) + m\eps$.
\end{proof}

This bound can be improved if we have a better upper bound on the number of
edges used in the cycles of $f'$.
Indeed, the algorithm in Section~\ref{section:goldberg} gives a
bound of $6k$, and converts the statement from an additive approximation to a
relative approximation. \note{Maybe not here; move to Sec.\ 4.}
Since our matching algorithm uses a 0-optimal (exact) solution, we do not
include a proof for approximation quality of $\eps$-optimal matchings. \note{Which means you don't have to explain.}


\section{Matching with the Hungarian algorithm}
\label{section:hung}

The Hungarian algorithm maintains a 0-optimal (initially empty) matching $M$,
and repeatedly augments by alternating augmenting paths of admissible edges
until $|M| = k$.
To this end, the algorithm maintains a set of feasible potentials $\pi$ and
updates them to find augmenting paths of admissible edges.
It maintains the invariant that matching edges are admissible.
Since there are $k$ augmentations and each alternating path is length at most
$2k-1$, the total time spent on bookkeeping the matching is $O(k^2)$.
This leaves the analysis of the subroutine which updates the potentials and
finds an admissible augmenting path, called the \emph{Hungarian search}.

\begin{algorithm}
\caption{Hungarian Algorithm}
\begin{algorithmic}[1]
\Function{Match}{$G = (A \cup B, E)$, $k$}
	\State $M \gets \emptyset$
	\State $\pi(v) \gets 0, \forall v \in A \cup B$
	\While{$|M| < k$}
		\State $\Pi \gets$ \Call{Hungarian-Search}{$G$, $M$, $\pi$}
		\State $M \gets M \oplus \Pi$
	\EndWhile
	\State\Return $M$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{theorem}[Hungarian algorithm time]
\label{theorem:hung_orig}
	Let $G = (A \cup B, A \times B)$ be an instance of geometric partial
	matching with $|A| = r \geq |B| = n$, and parameter $k \leq r$.
	Suppose the Hungarian search finds each augmenting path in $T(n, k)$
	time after a one-time $P(n, k)$ preprocessing time.
	Then, the Hungarian algorithm finds the optimal size $k$ matching in
	time $O(P(n, k) + k T(n, k) + k^2)$.
\end{theorem}

\subsection{Hungarian search}

Let $S$ be the set of vertices that can be reached from an unmatched $a \in A$
by admissible residual edges, initially the unmatched vertices of $A$.
The Hungarian search updates potentials in a Dijkstra's algorithm-like manner,
expanding $S$ until it includes an unmatched $b \in B$ (and thus an admissible
alternating augmenting path).
The ``search frontier'' of the Hungarian search is
$(S \cap A) \times (B \setminus S)$.
From the frontier, we \emph{relax} the edge with minimum reduced cost, changing
the duals such that the edge becomes admissible, and adding the opposite $B$
vertex into $S$.

The dual update uniformly decreases the reduced costs of the frontier edges.
Since $(a', b')$ is the minimum reduced cost frontier edge, the potential
update in line~\ref{line:hs_update} does not make any reduced cost negative,
and thus preserves the dual feasibility constraint for all edges.
The algorithm is shown below as Algorithm~\ref{algorithm:hung_hs}.

\begin{algorithm}
\caption{Hungarian Search (matching)}
\label{algorithm:hung_hs}
\begin{algorithmic}[1]
\Require{$\forall (a, b) \in M, c_\pi(a, b) = 0$}
\Statex %newline
\Function{Hungarian-Search}{$G = (A \cup B, E)$, $M$, $\pi$}
	\State $S \gets a \in (A \setminus V(M))$
	\Repeat
		\State $(a', b') \gets \argmin\{c_\pi(a, b) \mid (a, b) \in (S \cap A) \times (B \setminus S)\}$
		\State $\gamma \gets c_\pi(a', b')$
		\State $\pi(v) \gets \pi(v) + \gamma, \forall v \in S$
			\Comment{make $(a', b')$ admissible}
			\label{line:hs_update}
		\State $S \gets S \cup \{b'\}$
		\Statex %newline
		\If{$b' \not\in V(M)$} \Comment{$b'$ unmatched}
			\State $\Pi \gets$ alternating augmenting path in $S$ to $b'$
			\State\Return $\Pi$
		\Else \Comment{$b'$ is matched to some $a'' \in A \cap V(M)$}
			\State $S \gets S \cup \{a''\}$
		\EndIf
	\Until{$S = (A \cup B)$}
	\State\Return failure
\EndFunction
\end{algorithmic}
\end{algorithm}

By tracking the forest of relaxed edges (e.g. back pointers), it is
straightforward to recover the alternating augmenting path $\Pi$ once we reach
an unmatched $b' \in B$.
We make the following observation about the Hungarian search:

\begin{lemma}
\label{lemma:hungsearch_length}
	There are $\leq k$ edge relaxations before the Hungarian search finds
	an alternating augmenting path.
\end{lemma}
\begin{proof}
	Each edge relaxation either leads to a matched $B$ vertex (of which
	there are at most $k-1$), or finds an unmatched vertex and ends the
	search.
\end{proof}

In non-geometric graphs, the minimum edge is typically found by pushing all
encountered $(S \cap A) \times (B \setminus S)$ edges into a priority queue.
However, in the bipartite complete graph, this may take $\Theta(rn\polylog(n))$
time in each Hungarian search --- edges must be pushed into the queue even if
they are not relaxed.
We avoid this problem by finding the minimum edge using a \emph{bichromatic
closest pair} (BCP) query on additively weighted Euclidean distances,
for which there exist fast (poly-logarithmic query and update) dynamic data
structures.
The BCP problem is to find, between two point sets
$P, Q \subseteq \mathbb{R}^2$, the $p \in P$ and $q \in Q$ minimizing
$\|p - q\| - \omega(p) + \omega(q)$, for some real-valued vertex weights
$\omega(p)$; a perfect fit for reduced cost.
The state of the art for dynamic BCP data structures --- from Kaplan, Mulzer,
Roditty, Seiferth, and Sharir~\cite{KMRSS17} --- inserts and deletes points in
$O(\polylog(n))$ time, and answers queries in $O(\log^2 n)$ time.
The following lemma, combined with Theorem~\ref{theorem:hung_orig}, completes
the proof of Theorem~\ref{theorem:hung}.

\begin{lemma}
\label{lemma:hs_time}
	Using a dynamic BCP, we can implement Hungarian search with
	$T(n, k) = O(k\polylog(n))$ and $P(n, k) = O(n\polylog(n))$.
\end{lemma}
\begin{proof}
	We will maintain a BCP between $P = (S \cap A)$ and
	$Q = (B \setminus S)$.
	Changes to the BCP sets are entirely driven by changing $S$,
	i.e. updates to $S$ incur BCP insertions/deletions.
	We first analyze the bookkeeping outside of dual updates, and then
	show how dual updates can be done efficiently.

	\begin{enumerate}
	\item Let $S^t_0$ denote the initial set $S$ at the beginning of the
		$t$-th Hungarian search, i.e. the set of unmatched $A$ points
		after $t$ augmentations.
		At the very beginning of the Hungarian algorithm, we initialize
		$S^0_0 \gets A$ (meaning $P = A$ and $Q = B$), which is a
		one-time addition of $O(n)$ points into BCP.
		On each successive Hungarian search, $S^t_0$ shrinks as more
		and more $A$ points are matched.
		Assume for now that, at the beginning of the $(t+1)$-th
		Hungarian search, we are able to construct the $S^t_0$ from the
		previous iteration.
		To construct $S^{t+1}_0$, we simply remove the $A$ point that
		was matched by the $t$-th augmenting path.
		Thus, with that assumption, we are able to initialize $S$ in
		one BCP deletion operation per augmentation.

	\item During each Hungarian search, points are added to $P$ ($A$ points
		added to $S$) and removed from $Q$ ($B$ points added to $S$)
		--- at most one of each per edge relaxation.
		By Lemma~\ref{lemma:hungsearch_length} the number of relaxed
		edges is at most $k$, so the number of these BCP operations is
		also at most $k$.

	\item To obtain the assumption used in (1), we keep a log of the
		points added since $S^t_0$ in the last Hungarian search
		(i.e. those of (2)).
		After the augmentation, we use this log to delete the added
		vertices from $S$ and recover $S^t_0$.
		By the argument in (2) there are $O(k)$ of such points to
		delete, so reconstructing $S^t_0$ costs $O(k)$ BCP operations.
		% TODO instead of reversing a log, is persistence an easier solution to this?
	\end{enumerate}

	We spend a one-time fee of $P(n, k) = O(n \polylog(n))$ time to build
	the initial BCP.
	The number of BCP operations associated with each Hungarian search is
	$O(k)$, so the time spent on BCP operations in each Hungarian search
	is $O(k \polylog(n))$.

	We modify a trick from Vaidya~\cite{Vaidya89} to batch potential
	updates such that the dual updates we do perform can be charged to a
	BCP insertion or deletion.
	Throughout the course of the Hungarian algorithm, we maintain a value
	$\delta$ (initially 0) which aggregates dual changes.
	Vertices that are added to $S$ are saved into $P$ with weight
	$\omega(p) \gets \pi(p) - \delta$.
	When the points of $S$ have their duals increased in (2), we instead
	raise $\delta \gets \delta + c_\pi(\hat{a}, \hat{b})$.
	Thus, the ``true'' potential for any point in $S$ is
	$\omega(p) + \delta$.
	For points outside $S$ (i.e. $B \setminus S$), we simply use the true
	potential as the BCP weight.
	Since all $S \cap A$ BCP weights are uniformly offset from their
	potential by $\delta$, this change does not alter the BCP result.
	Once a point is removed from $S$, we update its true potential
	as $\pi(p) \gets \omega(p) + \delta$.

	Obviously, the number of updates to $\delta$ is equal to the number of
	edge relaxations, which is $O(k)$ per Hungarian search.
	The number of times we have to save the true potential is bounded by
	the number times we remove a point from $S$.
	By the previous argument (2), this is $O(k)$ per Hungarian search as
	well.
	The total time for potential updates per Hungarian search is therefore
	$O(k)$.
	Overall, the time per Hungarian search is $T(n, k) = O(k\polylog(n))$.
\end{proof}


\section{Matching with the Goldberg~{\etal} algorithm}
\label{section:goldberg}

The basis of the algorithm in this section is a \emph{cost-scaling} algorithm
for unit-capacity min-cost flow from \cite{GHKT17}.
Before describing the algorithm, we first give a linear-time reduction from
min-cost matching to unit-capacity min-cost flow, which allows us to apply the
Goldberg~{\etal} algorithm to partial matching.

\subsection{MPM to unit-capacity MCF reduction}
\label{subsection:mcm_mcf_reduction}

For a partial matching problem on $G = (A \cup B, E_0)$ with parameter $k$, we
direct the bipartite edges of $E_0$ from $(A \to B)$, with costs equal to the
original cost $c(a, b)$ and capacity 1.
Next, we add a dummy vertex $s$ with arcs $(s, a)$ to every $a \in A$,
and respectively a dummy vertex $t$ with arcs $(b, t)$ for each $b \in B$,
all with arc cost 0 and capacity 1.
For each of the above arcs $(v, w)$, we also add a reverse arc $(w, v)$ with
cost $c(w, v) = -c(v, w)$ and capacity 0.
Let the complete set of arcs be $E$, and $V = A \cup B \cup \{s, t\}$.
Set $\fsupply(s) = k$, $\fsupply(t) = -k$, and $\fsupply(v) = 0$ for all other
vertices.
Let the resulting graph be $H = (V, E)$.

\begin{observation}
\label{observation:dag}
	The arcs of $H$ with positive capacity form a directed acyclic graph.
\end{observation}

In other words, there will be no cycles of positive flow in circulations on
$H$.
With this, we can show that the number of arcs used by any integer pseudoflow
in $H$ (with $O(k)$ excess) is $O(k)$.

\begin{lemma}
\label{lemma:reduction_count}
	Let $f$ be an integer pseudoflow in $H$ with $O(k)$ excess, and let
	$E_{>0}(f) = \{(v, w) \mid f(v, w) > 0\}$.
	Then, $|E_{>0}(f)| = O(k)$.
\end{lemma}
\begin{proof}
	By Observation~\ref{observation:dag}, the positive-flow edges of $f$
	do not contain a cycle.
	Thus, the flow decomposition of $f$ is a series of paths, each of which
	can create a single unit of excess if it does not terminate at $t$.
	By assumption, then, there are $O(k)$ such paths.
	The maximum length of any path of positive-flow arcs in $H$ is 3,
	by the capacities in the construction.
	We conclude that the number of positive flow arcs in $f$ is $O(k)$.
\end{proof}

It is straightforward to show that any integer circulation on $H$ uses exactly
$k$ of the $(A \to B)$ arcs, which correspond to the edges of a size $k$
matching.
For a circulation $f$ in $H$, we use $M_f \subseteq E$ to denote the
corresponding matching.
Observe that $\cost(f) = \cost(M_f)$, so an $\alpha$-approximation to the MCF
problem on $H$ is an $\alpha$-approximation to the matching problem on $G$.

For cost approximation, we can improve Lemma~\ref{lemma:mcf_cost} on $H$.
Note that for integer-valued (e.g. unit) capacities, there is always an
integer-valued optimal circulation.
\begin{lemma}
\label{lemma:goldberg_cost_add}
	Let $f$ an $\eps$-optimal integer circulation in $H$, and $f^*$ an
	optimal integer circulation for $H$.
	Then, $\cost(f) \leq \cost(f^*) + 6k\eps$.
\end{lemma}
\begin{proof}
	We label the arcs of $H_f$ as follows: \emph{forward arcs} directed
	from $s \to A$ or $A \to B$ or $B \to t$, and \emph{reverse arcs} in
	the opposite directions.
	Observe that a residual cycle $\Gamma$ must have exactly half of its
	edges be reverse arcs.
	The reverse arcs may either be (i) on one of the $M_f$ edges or else
	(ii) between $\{s\} \times A$ or (iii) between $B \times \{t\}$.
	If it is of type (ii) or (iii), there is an adjacent type (i) reverse
	arc.
	Thus, we can charge the reverse arcs of $\Gamma$ to $M_f \cap \Gamma$
	edges with at most 3 charge per edge of $M_f \cap \Gamma$.
	We can then charge all arcs of $f' = (f^* - f) = \sum \Gamma_i$ to
	$M_f$ with at most 6 charge per $M_f$ edge.
	As $|M_f| = k$, the number of arcs in $f'$ is at most $6k$.
	The rest of the argument proceeds as in Lemma~\ref{lemma:mcf_cost}.
\end{proof}

Suppose we scaled arc costs (via uniform scaling of the input points) such that
the minimum cost (closest pair distance) is 1.
Then, $\cost(f^*) \geq k$, and we can turn Lemma~\ref{lemma:goldberg_cost_add}
into a relative approximation.

\begin{corollary}
\label{corollary:flow_approx}
	Let $f$ an $\eps$-optimal integer circulation in $H$, and $f^*$ an
	optimal integer circulation for $H$.
	Suppose costs are scaled such that $\min \|a - b\| = 1$.
	Then, $\cost(f) \leq (1 + 6\eps) \cost(f^*)$.
\end{corollary}

\begin{corollary}
\label{corollary:match_approx}
	Let $f$ an $(\eps'/6)$-optimal integer circulation in $H$, and $M^*$ an
	optimal size $k$ matching of $G$.
	Suppose costs are scaled such that $\min \|a - b\| = 1$.
	Then, $\cost(M_f) \leq (1 + \eps') \cost(M^*)$.
\end{corollary}

In other words, a $(\eps'/6)$-optimal circulation is sufficient for a
$(1 + \eps')$-approximate matching.

\subsection{Algorithm description}

The Goldberg~{\etal}~\cite{GHKT17} algorithm is based on \emph{cost-scaling} or
\emph{successive approximation}, originally due to Goldberg and
Tarjan~\cite{GT90}.
The algorithm finds $\eps$-optimal circulations for geometrically shrinking
values of $\eps$.
Each period where $\eps$ holds constant is called a \emph{scale}.
Once $\eps$ is sufficiently small, the $\eps$-optimal flow is a suitable
approximation or even optimal when costs are integer~\cite{GT90,GHKT17}.
We present this algorithm as an approximation is because costs in geometric
partial matching (i.e. Euclidean distances) are generally not integer.

\begin{algorithm}
\caption{Cost-Scaling MCF}
\begin{algorithmic}[1]
\Function{MCF}{$H$, $\eps'$}
	\State $\eps \gets kC$
	\State $f \gets 0$
	\State $\pi \gets 0$
	\Repeat
		\State $(f, \pi) \gets$ \Call{Scale-Init}{$H$, $f$, $\pi$}
		\State $(f, \pi) \gets$ \Call{Refine}{$H$, $f$, $\pi$}
		\State $\eps \gets \eps/2$
	\Until{$\eps \leq \eps'/6$}
	\State\Return $f$
\EndFunction
\end{algorithmic}
\end{algorithm}

Note that the 0 flow is trivially $kC$-optimal for $H$.
At the beginning of each scale, \textsc{Scale-Init} takes the previous
circulation (now $2\eps$-optimal) and transforms it into an $\eps$-optimal
pseudoflow with $O(k)$ excess.
The rest of the scale, in \textsc{Refine}, reduces the excess in this
pseudoflow to 0, making an $\eps$-optimal circulation.
The bulk of this section will describe and analyze \textsc{Scale-Init} and
\textsc{Refine}.

For now, we analyze the number of scales (iterations of the outer loop).
Initially $\eps = kC$, and the algorithm is stopped once $\eps \leq \eps'/6$.
Thus, the number of scales is $O(\log(kC/\eps'))$.
For bichromatic matching, there is a simple way to preprocess the point set
such that $C = O(n^2)$, effectively, by Sharathkumar and Agarwal~\cite{SA12}.
Using this preprocessing gives us $O(\log(n/\eps'))$ scales, instead.
We briefly describe this preprocessing step at the end of this section.

\begin{lemma}
\label{lemma:goldberg_scales}
	The cost-scaling algorithm finds a $(1 + \eps')$-approximate matching
	after $O(\log(n/\eps'))$ scales.
\end{lemma}

\subsection{\textsc{Scale-Init}}

\begin{algorithm}
\caption{Scale Initialization}
\label{algorithm:scale_init}
\begin{algorithmic}[1]
\Function{Scale-Init}{$H$, $f$, $\pi$}
	\State $\forall a \in A, \pi(a) \gets \pi(a) + \eps$
	\State $\forall b \in B, \pi(b) \gets \pi(b) + 2\eps$
	\State $\pi(t) \gets \pi(t) + 3\eps$
	\Statex %newline
	\ForAll{$(v, w) \in E_f$}
		\If{$c_\pi(w, v) < -\eps$}
			\State $f(v, w) \gets 0$
		\EndIf
	\EndFor
	\State\Return $(f, \pi)$
\EndFunction
\end{algorithmic}
\end{algorithm}

The procedure is described in Algorithm~\ref{algorithm:scale_init}.
Let the $H_f$ arcs directed from $s \to A$ or $A \to B$ or $B \to t$ be
\emph{forward arcs}, and let those in the opposite directions be
\emph{reverse arcs}.
The first 4 lines of \textsc{Scale-Init} raise the reduced cost of each
forward arc by $\eps$, therefore making all forward arcs $\eps$-optimal.
For example, a forward arc of $A \to B$ now has reduced cost
\begin{equation*}
	c(a, b) - (\pi(a) + \eps) + (\pi(b) + 2\eps)
	= c_\pi(a, b) + \eps
	\geq -2\eps + \eps
	= -\eps.
\end{equation*}
In the lines after, we deal with the reduced cost of reverse arcs by simply
de-saturating them if they violate $\eps$-optimality.
Note that forward arcs will not be de-saturated in this step, since they are
now $\eps$-optimal.

\begin{lemma}
\label{lemma:scale_init}
	In $O(n)$ time, \textsc{Scale-Init} turns a $2\eps$-optimal circulation
	into an $\eps$-optimal pseudoflow with $O(k)$ excess.
\end{lemma}
\begin{proof}
	The potential updates affect every vertex except $s$,
	so this takes $O(n)$ time.
	As for the arc de-saturations, every reverse arc is induced by positive
	flow on a forward arc, and the number of positive flow edges in $f$ is
	$O(k)$.
	The total number of edges that get examined by the loop is therefore
	$O(k)$.
	In total, the time taken is $O(n)$.

	For the amount of excess, notice that new excess is only created due
	to the de-saturations of reverse arcs.
	Because the graph is unit-capacity, each de-saturation creates one unit
	of excess.
	There are $O(k)$ reverse arcs possible, so the total created excess
	must be $O(k)$.
\end{proof}

\subsection{\textsc{Refine}}

\textsc{Refine} is implemented using a primal-dual augmentation algorithm,
which sends improving flows on admissible edges like the Hungarian algorithm.
Unlike the Hungarian algorithm, it uses blocking flows instead of augmenting
paths.

\begin{algorithm}
\caption{Refinement}
\begin{algorithmic}[1]
\Function{Refine}{$H = (V, E)$, $f$, $\pi$}
	\While{$\sum_{v \in V} |e_f(v)| > 0$}
		\State $\pi \gets$ \Call{Hungarian-Search2}{$H$, $f$, $\pi$}
		\State $f' \gets$ \Call{DFS}{$H$, $f$, $\pi$}
			\Comment{$f'$ is an admissible blocking flow}
		\State $f \gets f + f'$
	\EndWhile
	\State\Return $(f, \pi)$
\EndFunction
\end{algorithmic}
\end{algorithm}

Using the properties of blocking flows and the unit-capacity input graph,
Goldberg~{\etal} prove that there are $O(\sqrt{k})$ blocking flows before
excess becomes 0.

\begin{lemma}[Goldberg~{\etal}~\cite{GHKT17} Lemma 3.11 and Section 6]
	Let $f$ be a pseudoflow in $H$ with $O(k)$ excess.
	There are $O(\sqrt{k})$ blocking flows before excess is 0.
\end{lemma}

We can use this, alongside Lemma~\ref{lemma:reduction_count} to argue that the
amount of time spent updating the flow within \textsc{Refine} is
$O(k\sqrt{k})$.

Each step of \textsc{Refine} finds an admissible blocking flow in two stages.
\begin{enumerate}
\item A \emph{Hungarian search}, which updates duals in a Dijkstra-like
	manner until there exists an excess-deficit path of admissible edges.
	There are slight differences from the Hungarian algorithm's ``Hungarian
	search,'' but the final running time is identical.
	We call the procedure \textsc{Hungarian-Search2} to distinguish.

\item A \emph{depth-first search} (\textsc{DFS}) through the set of admissible
	edges to construct an admissible blocking flow.
	It suffices to repeatedly extract admissible augmenting paths until
	no more admissible excess-deficit paths remain.
	By definition, the union of such paths is a blocking flow.
\end{enumerate}
For \textsc{Hungarian-Search2}, we again use a dynamic BCP data structure to
accelerate the Hungarian search after a once-per-\textsc{Refine} preprocessing.
To perform \textsc{DFS} quickly, we can use a dynamic \emph{nearest-neighbor}
(NN) data structure, to discover admissible edges without handling the set of
admissible edges explicitly.
This is applied in a similar way as the BCP is for Hungarian search.

\begin{lemma}
	Suppose \textsc{Hungarian-Search2} can be implemented in $T_1(n, k)$
	time after a once-per-\textsc{Refine} $P_1(n, k)$ time preprocessing,
	and respectively \textsc{DFS} in $T_2(n, k)$ time after $P_2(n, k)$
	preprocessing.
	Then, \textsc{Refine} can be implemented in
	$O(P_1(n, k) + P_2(n, k) + \sqrt{k}[T_1(n, k) + T_2(n, k)] + k\sqrt{k})$
	time.
\end{lemma}

As we will show shortly (Lemmas~\ref{lemma:goldberg_hs_time},
\ref{lemma:goldberg_dfs_time}), the total running time for \textsc{Refine}
is ultimately $O((n + k\sqrt{k})\polylog(n))$.
Combining with Lemmas~\ref{lemma:goldberg_scales} and \ref{lemma:scale_init}
completes the proof of Theorem~\ref{theorem:gmcm}.

\subsubsection{Hungarian search}

%TODO add in relaxation decisions for 2-paths and 3-paths
\begin{algorithm}
\caption{Hungarian Search (cost-scaling)}
\begin{algorithmic}[1]
\Function{Hungarian-Search2}{$H = (V, E)$, $f$, $\pi$}
	\State $S \gets \{v \in V \mid e_f(v) > 0\}$
	\Repeat
		\State $\Pi \gets \argmin\{c_\pi(v, w) \mid \text{$\Pi$ is an edge between non-empty vertices of $S \times V \setminus S$, or empty 2-/3-path out of $S$}\}$
		\State $\gamma \gets c_\pi(\Pi)$
			\Comment{relax the minimum edge or empty path}
		\If{$\gamma > 0$}
			\Comment{make $\Pi$ admissible if it isn't}
			\State $\pi(v) \gets \pi(v) + \gamma\lceil\frac{\gamma}{\eps}\rceil, \forall v \in S$
		\EndIf
		\State $S \gets S \cup \Pi$
		\Statex %newline
		\State Let $\Pi = v_1, \ldots, v_\ell$
		\If{$e_f(v_\ell) < 0$} \Comment{$\Pi$ reached a deficit}
			\State\Return $(f, \pi)$
		\EndIf
	\Until{$S = (A \cup B)$}
	\State\Return failure
\EndFunction
\end{algorithmic}
\end{algorithm}

Compared to \textsc{Hungarian-Search}, this algorithm does not maintain
admissibility as an invariant for edges with $f(v, w) > 0$, so these edges are
not relaxed immediately in a special case.
Instead, we store the $O(|E_{>0}(f)|)$ of them leaving $S$ in a min heap and
compare their reduced costs with the BCP result, relaxing the edge with lower
reduced cost.
Uniformly raising the potentials of $S$ preserves reduced costs for arcs within
$S$ and decreases them for arcs leaving $S$.
Raising potentials in intervals of $\eps$ will also not decrease a reduced
cost to less than $-\eps$, so arcs leaving $S$ still satisfy $\eps$-optimality.

Vertices of $A \cup B$ with $e_f(v) = 0$ and 0 incoming and outgoing flow
cannot be charged to $k$ using the previous analysis, so the algorithm treats
these \emph{empty vertices} separately.
Namely, there is no edge with $f(e) > 0$ adjacent to an empty vertex,
reaching an empty vertex does not terminate the search, and there may be
$\Omega(n)$ empty vertices at once (consider $H_{f = 0}$, the residual graph
of the empty flow).
We use $A_\emptyset$ and $B_\emptyset$ to denote the empty vertices of $A$ and
$B$ respectively.
For an empty vertex $v$, either residual in-degree ($v \in A_\emptyset$) or
residual out-degree ($v \in B_\emptyset$) is 1.
Instead of querying an empty vertex during the search, we shortcut it using the
length 2 paths to/from non-empty vertices, called \emph{empty 2-paths}.
For example, if $v \in A_\emptyset$ (resp. $v \in B_\emptyset$), then its empty
2-paths have the form $(s, v, b)$ (resp. $(a, v, t)$) for each
$b \in B \setminus B_\emptyset$ (resp. $a \in A \setminus A_\emptyset$).
We say that $(s, v, b)$ is an empty 2-path \emph{surrounding} empty vertex $v$.
Separately, we consider the length 3 $s$-$t$ paths that pass through two empty
vertices, called \emph{empty 3-paths}.
As with 2-paths, we say an empty 3-path $(s, v_1, v_2, t)$ \emph{surrounds}
$v_1 \in A_\emptyset$ and $v_2 \in B_\emptyset$.

Each relaxation (Line
Relaxation steps involving an empty 2- or 3-path will relax the entire path
at once, moving all vertices of the path into $S$.
Relaxation steps that do not involve an empty 2- or 3-path are called
\emph{non-empty}.

Consider an empty 2-path $(s, v, b)$ that surrounds $v$.
Since $v$ has zero excess/deficit, the search cannot ``make progress'' through
$v$ until it reaches $b$.
Since reduced costs telescope for residual paths, the reduced cost of
$(s, v, b)$ does not depend on the potential of $v$.
\begin{equation*}
	c_\pi((s, v, b)) = c_\pi(s, v) + c_\pi(v, b) = c(v, b) - \pi(s) + \pi(b)
\end{equation*}
Thus, we can safely ignore the potential of $v$ until it ceases to be
empty, e.g. after an augmentation across one of its empty paths.
At that point, we can infer $\pi(v)$ from the potentials of the empty 2-path
augmented through (this path must be admissible).
Before we go into the details of updating the sets of empty vertices and their
potentials, we describe the mechanism for querying the minimum-reduced cost
empty 2- and 3-paths.

When the search has $s \in S$, we can query the minimum-reduced cost empty
2-path surrounding $A_\emptyset$ vertices using a data structure
$D_\emptyset(A)$ maintaining
$BCP(P = A_\emptyset, Q = (B \setminus B_\emptyset) \setminus S)$ with weights
$\omega(p) = \pi(s)$ for all $p \in P$, and $\omega(q) = \pi(q)$ for all
$q \in Q$.
It is simple to verify that if $(p, q)$ is the BCP of $P, Q$ above, then its
BCP distance is precisely the reduced cost of the 2-path $(s, p, q)$.
We can build similar query data structures for other empty 2-paths and empty
3-paths, also reporting a pair whose weighted distance is equal to the reduced
cost of the corresponding empty 2- or 3-path.
Empty 2-paths surrounding $B_\emptyset$ vertices can be queried using
$D_\emptyset(B)$ which maintains
$BCP(P = (A \setminus A_\emptyset) \cap S, Q = B_\emptyset)$ with weights
$\omega(p) = \pi(p)$ for all $p \in P$, and $\omega(q) = \pi(t)$ for all
$q \in Q$.
We query $D_\emptyset(B)$ so long as $t \not\in S$.
Lastly, the minimum-reduced cost empty 3-path can be queried using a data
structure $D_\emptyset(A, B)$ maintaining
$BCP(P = A_\emptyset \setminus S, Q = B_\emptyset)$ with weights
$\omega(p) = \pi(s)$ for all $p \in P$, and $\omega(q) = \pi(t)$ for all
$q \in Q$.
We query $D_\emptyset(A, B)$ only while $s \in S$ and $t \not\in S$.

%TODO describe/bound the update process for each data structure:
	% how to find them:
	% empty both: BCP with all empty vertices, using s/t potentials
	%	active as long as s reached, t unreached
	%	updates according to S with deletions
	% empty a: BCP with empty A to nonempty unreached B, using s/b potentials
	%	active as long as s reached
	%	updates according to S with deletions in B
	% empty b: BCP with with nonempty reached A to empty unreached B, using a/t potentials
	%	active as long as t unreached
	%	updates according to S with insertions in A

	% ^ the empty sets will only change through empty relaxations

	% assuming we can find them, how many empty a, b, and both?
	% only one empty both per h.s., starting at s and adding t.
	% empty a leads to a non-empty b, charge to adjoining b support or deficit
	% empty b comes from a non-empty a, charge to adjoining a support or excess

	% how to find empty both? potentials at s, t plus BCP on empty A x empty B
	% how to find empty a? potential at s, min of potentials of nonempty B
	% how to find empty b? potential at t, max of potentials of nonempty A

	% empty/nonempty may only change during augmentation, and only on nodes augmented through
	% charge empty/nonempty d.s. updates to the blocking flow nodes
	% \eps is fixed at the current scale
	% potentials MUST be recovered during augmentation and at scale end
	% seems like fixing them to \pi(s) or \pi(t) is correct; certainly will not violate feas if \pi(s) doesn't




In the next few lemmas, we bound the number of relaxations of each type.
This will provide a time bound for the Hungarian search in terms of the
number of relaxations, each of which take $O(1)$ BCP queries and updates.

\begin{lemma}
\label{lemma:goldberg_hs_length1}
	There are $O(k)$ non-empty relaxations in \textsc{Hungarian-Search2}
	before a deficit vertex is reached.
\end{lemma}
\begin{proof}
	Let $E_{>0}(f) = \{(v, w) \in E \mid f(v, w) > 0\}$.
	Each edge relaxation adds a new vertex to $S$.
	The vertices of $V \setminus S$ fall into several categories:
	(i) $s$ or $t$, (ii) $A$ or $B$ vertex with 0 imbalance, and (iii) $A$
	or $B$ vertex with deficit ($S$ contains all excess vertices).
	The number of vertices in (i) and (iii) is $O(k)$, leaving us to bound
	the number of (ii) vertices.

	An $A$ or $B$ vertex with 0 imbalance must have an even number of
	$E_{>0}(f)$ edges.
	There is either only one positive-capacity incoming edge (for $A$) or
	outgoing edge (for $B$), so this quantity is either 0 or 2.
	By the non-emptiness assumption, it must be 2.
	We charge 0.5 to each of the two $E_{>0}(f)$ edges;
	the edges of $E_{>0}(f)$ have no more than 1 charge each.
	Thus, the number of (ii) vertex relaxations is $O(|E_{>0}(f)|)$.
	%TODO prove that |E_{>0}(f)| = O(k)
\end{proof}

\begin{lemma}
\label{lemma:goldberg_hs_length2}
	There are $O(k)$ empty 2- and 3-path relaxations in
	\textsc{Hungarian-Search2} before a deficit vertex is reached.
\end{lemma}
\begin{proof}
	There is only one empty 3-path relaxation, since $t$ can only be added
	to $S$ once.
	This is also the case for the empty 2-paths surrounding a $B_\emptyset$
	vertex.

	On the other hand, the relaxation of an empty 2-path surrounding an
	$A_\emptyset$ vertex adds some non-empty
	$b \in B \setminus B_\emptyset$ into $S$.
	By definition, $b$ must either have deficit or an adjacent edge with
	$f(e) > 0$.
	We charge this relaxation to $b$ if it is deficit, or the adjacent
	$f(e) > 0$ edge otherwise.
	No $f(e) > 0$ edge is charged more than twice, therefore the total
	number of empty 2-path relaxations surrounding $A_\emptyset$ vertices
	is $O(|E_{>0}(f)|)$.
	%TODO bound size of flow support in k
\end{proof}



%TODO




\begin{lemma}
\label{lemma:goldberg_hs_time}
	Using a dynamic BCP, we can implement \textsc{Hungarian-Search2} with
	$T_1(n, k) = O(k\polylog(n))$ and $P_1(n, k) = O(n\polylog(n))$.
\end{lemma}
\begin{proof}
	Like for matchings, we use a BCP to find the argmin quickly;
	we maintain $P = (S \cap A)$ and $Q = (B \setminus V)$ using weights
	$\omega(v) = \pi(v) - \delta$, and increase $\delta$ in lieu of
	increasing the potential of all $S$ vertices.
	Using Lemma~\ref{lemma:hs_time} as a basis, we first analyze the number
	of BCP operations over the course of \textsc{Hungarian-Search2}.
	\begin{enumerate}
	\item Let $S^t_0$ denote the initial set $S$ at the beginning of the
		$t$-th Hungarian search, i.e. the set of $v \in V$ with
		$e_f(v) > 0$ after $t$ blocking flows.
		Assume for now that, at the beginning of the $(t+1)$-th
		Hungarian search, we have on hand the $S^t_0$ from the
		previous iteration.
		To construct $S^{t+1}_0$, we remove the vertices that had
		excess decreased to 0 by the $t$-th blocking flow.
		Thus, with that assumption, we are able to initialize $S$ at
		the cost of one BCP deletion per excess vertex, which sums to
		$O(k)$ over the entire course of \textsc{Refine}.
	\item During each Hungarian search, a vertex entering $S$ may cause $P$
		or $Q$ to update and incur one BCP insertion/deletion.
		Like before, we can charge these to the number of edge
		relaxations over the course of \textsc{Hungarian-Search2}.
		%TODO ref lemma hs_length
	\item Like before, we can meet the assumption in (1) by rewinding a log
		of point additions to $S$, and recover $S^t_0$.
		%TODO ref lemma for bounding the number of rewinds
	\end{enumerate}










	Unlike matchings, there are now some arcs that are eligible for the
	minimum but not ``captured'' by the BCP.
	Specifically, it makes no sense to place $s$ or $t$ in the BCP
	(they do not correspond to points in the plane), or the arcs from
	$B \to A$ (arcs of $(S \cap B) \times (V \setminus S)$ are not residual
	unless there is positive flow on the respective $A \to B$ arc).
	We label these special classes of arcs (i) $E_s^+$ and $E_s^-$,
	residual arcs with $s$ on the head and tail respectively, (ii)
	$E_t^+$ and $E_t^-$, residual arcs with $t$ on the head and tail
	respectively, and (iii) $E_{BA}$, $B \to A$ residual arcs.
	There are $O(r)$ arcs in $E_s^+$ and $E_s^-$, $O(n)$ arcs in $E_t^+$
	and $E_t^-$, and $O(k)$ arcs in $E_{BA}$
	(by Lemma~\ref{lemma:reduction_count}).
	We maintain a min-heap for each arc set on the same distances used
	by the BCP ($c(v, w) - \omega(v) + \omega(w)$).
	Until $s$ (resp. $t$) is included into $S$, we ``deactivate'' $E_s^+$
	(resp. $E_t^+$) and do not query it for the minimum.
	Once $s$ (resp. $t$) is added, we activate $E_s^+$ (resp. $E_t^+$) and
	deactivate $E_s^-$ (resp. $E_t^-$).
	These activations/deactivations occur once per Hungarian search, since
	vertices do not leave $S$ once they enter.
	When evaluating the argmin, we take the minimum over all active heaps
	plus the BCP.

	We can ultimately charge all heap operations to BCP operations, and
	see that there are $O(k)$ total.
	When a vertex moves into $S$, it begets a heap operation in addition
	to the BCP deletion.
	For example, if $a \in A$ moves into $S$, $(s, a)$ should be deleted
	from $E_t^-$, or $(a, s)$ should be added to $E_t^+$


	For potential updates, we use the same trick as in
	Lemma~\ref{lemma:hs_time} to lazily update potentials after vertices
	leave $S$.
	To remind, these potential updates were bounded by the number of times
	a point left $S$.

\end{proof}


\subsubsection{Depth-first search}

The depth-first search is similar to \textsc{Hungarian-Search2} in that it
relies on the relaxation of a minimum-reduced cost edge.
%TODO simplify dfs, also the empty vertex stuff may complicate this
\begin{algorithm}
\caption{Depth-first search}
\begin{algorithmic}[1]
\Function{DFS}{$H = (V, E)$, $f$, $\pi$}
	\State $f' \gets 0$.
	\State $S \gets \{v \in V \mid e_f(v) > 0\}$
	\State $P \gets \emptyset$
	\Repeat
		\State $v' \gets$ \Call{Pop}{$P$}
		\If{$e_f(v') < 0$}
			\Comment{if we reached a deficit, save the path to $f'$}
			\State add to $f'$ a unit flow on the path $P$

			\State $P \gets \emptyset$
		\EndIf

		\Statex %newline
		\State $w' \gets \argmin\{c_\pi(v', w) \mid w \in V \setminus S\}$
		\State $\gamma \gets c_\pi(v', w')$
		\Statex %newline
		\If{$\gamma \leq 0$}
			\Comment{if $(v', w')$ is admissible, extend the current path}
			\State $S \gets S \cup \{w'\}$

			\State $P \gets \Call{Push}{$P$, $w'$}$

		\EndIf




		\If{$e_f(w') < 0$} \Comment{$w'$ is a deficit}
			\State\Return $(f, \pi)$
		\EndIf
	\Until{$S = \emptyset$}
	\State\Return failure
\EndFunction
\end{algorithmic}
\end{algorithm}

%TODO is this still fine? with the empty path stuff?

\begin{lemma}
\label{lemma:goldberg_dfs_time}
	Using a dynamic NN, we can implement \textsc{DFS} with
	$T_2(n, k) = O(k\polylog(n))$ and $P_2(n, k) = O(n\polylog(n))$.
\end{lemma}
\begin{proof}
%TODO
\end{proof}








\subsection{Preprocessing for $C = O(n^2)$}

%TODO
\begin{lemma}[Sharathkumar, Agarwal]
	In $O(n\log n)$ time, we can preprocess $A, B$ by partitioning into
	$(A_1, B_1), \ldots, (A_\ell, B_\ell)$ such that
	\begin{enumerate}
	\item each $(A_i, B_i)$ has $|A_i| = |B_i|$,
	\item the union of optimal matching solutions on $(A_i, B_i)$
		is an optimal matching for $A, B$, and
	\item the spread of $(A_i, B_i)$ is $O(n^2)$.
	\end{enumerate}
\end{lemma}






\section{Unbalanced Transportation}

% definitions
% introduce the excess scaling algorithm/Orlin's
% time per hungarian search
% handling problem cases (stars, singletons)


{
\bibliographystyle{abbrv}
\bibliography{ref}
}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
