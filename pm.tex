%!TEX encoding = UTF-8 Unicode
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[hmargin=1in,vmargin=1in]{geometry}

\usepackage[dvipsnames,usenames]{xcolor}

\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage{euscript}
\usepackage{mathpazo}
\usepackage[scaled=.90]{berasans,beramono}

%\usepackage{epsfig}
%\usepackage{floatflt}
\usepackage{graphicx}

\usepackage{microtype}
\usepackage{subcaption}
\usepackage{xspace}
\usepackage[shortlabels, inline]{enumitem}

\usepackage{latexsym,amsmath,amssymb,amsthm}
\usepackage{algorithm,algorithmicx}
\usepackage[noend]{algpseudocode}
\usepackage{mathtools} % for \coloneqq

\usepackage[title]{appendix}

\usepackage{ifpdf}

%\graphicspath{{fig/}}

%\DeclareGraphicsExtensions{.pdf}

%\ifpdf
%\else
%   \DeclareGraphicsExtensions{.eps}
%\fi

\def\etal{\textsl{et~al.}}
\def\polylog{\mathop{\mathrm{polylog}}}
\def\eps{\varepsilon}
\def\softO{\widetilde{O}}
\def\bd{{\partial}}
\def\reals{\mathbb{R}}
\def\ints{\mathbb{N}}
\def\flr#1{{\lfloor #1\rfloor}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\def\tsupply{\lambda}
\def\fsupply{\phi}

\def\Refine{\textsc{Refine}}
\def\Update{\textsc{Update}}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{observation}{Observation}
\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}

\newcommand{\lemlab}[1]{\label{lem:#1}}
\newcommand{\figlab}[1]{\label{fig:#1}}
\newcommand{\theolab}[1]{\label{theo:#1}}
\newcommand{\corlab}[1]{\label{cor:#1}}
\def\lemref#1{Lemma~\ref{lemma:#1}}
\def\theoref#1{Theorem~\ref{theo:#1}}
\def\corref#1{Corollary~\ref{cor:#1}}
\def\figref#1{Figure~\ref{fig:#1}} \def\secref#1{Section~\ref{sec:#1}}

\def\parent{\operatorname{par}}
\def\cost{\operatorname{cost}}


\makeatletter
\long\def\@makecaption#1#2{
    \vskip 10pt
    \setbox\@tempboxa\hbox{{\footnotesize {\bf #1.} #2}}
    \ifdim \wd\@tempboxa >\hsize         % IF longer than one line:
        {\footnotesize {\bf #1.} #2\par}% THEN set as ordinary paragraph.
      \else                              %   ELSE  center.
        \hbox to\hsize{\hfil\box\@tempboxa\hfil}
    \fi}
%\dbltextfloatsep 18pt plus 2pt minus 4pt   % was 20pt plus 2pt minus 4pt
%\textfloatsep 18pt plus 2pt minus 4pt      % was 20pt plus 2pt minus 4pt
\makeatother

% ----------------------------------------------------------------------
%  Notes to myself.  The margin flags are broken, thanks to an
%  incompatibility with the geometry package.
% ----------------------------------------------------------------------
\def\n@te#1{\textsf{\boldmath \textbf{$\langle\!\langle$#1$\rangle\!\rangle$}}\leavevmode}
\def\note#1{\textcolor{red}{\n@te{#1}}}


%----------------------------------------------------------------------
% 'cramped' list style, stolen from Jeff Vitter.  Doesn't always work.
%----------------------------------------------------------------------
\def\cramped
  {\parskip\@outerparskip\@topsep\parskip\@topsepadd2pt\itemsep0pt
}


%% METAFILE
\title{ Geometric Partial Matching and Unbalanced Transportation %
\date{\today} % replace with date?
\author{
Pankaj K.\ Agarwal
\and
Allen Xiao
}
}


\begin{document}

\maketitle

\section{Introduction}

Consider the problem of finding a minimum-cost bichromatic matching between
a set of red points $A$ and a set of blue points $B$ lying in the plane,
where the cost of a matching edge $(a, b)$ is the Euclidean distance
$\|a - b\|$;
in other words, the minimum-cost bipartite matching problem on the Euclidean
complete graph $G = (A \cup B, A \times B)$.
Let $r$ be the number of vertices in $A$, and $n$ be the number of vertices in $B$.
Without loss of generality assume that $r \leq n$.
We consider the problem of \emph{partial matching}, where the task is to
find the minimum-cost matching of size $k$ (which by definition is at most $r$).
When $k = r = n$, we say the matching instance is \emph{balanced}
and call the problem \emph{perfect matching} or the \emph{assignment problem}.
When $k = r < n$ ($A$ and $B$ have different sizes, but the matching is
maximal), we say the matching instance is \emph{unblanced}.
\note{Don't mix up the definition of \emph{balanced} and \emph{perfect}; the former is between $r$ and $n$, where the latter is between $k$ and $r$.}
Partial matching generalizes both perfect matching and unbalanced matching.
We will refer to the geometric problem as \emph{geometric partial matching}.
\text{Maybe bad nameing; there is nothing geometric about this name.}

% \begin{TODO}
% Previous work
% \begin{itemize}\itemsep=0pt
% 	\item on matching
% 	\item on geometric matching
% 	\item on unbalanced/partial problems (GHKT, the push-relabel one, the tech report)
% \end{itemize}
% \noindent\textcolor{blue}{[Hsien: State your TODO list explicitly in the pdf file so that it's easier to read.  Make everything that you are planning to do, and put priorities on them.]}
% \end{TODO}


\subsection{Contributions}

In this paper, we present two algorithms for geometric partial matching
that are based on fitting nearest-neighbor (NN) and geometric closest pair
(BCP) oracles into primal-dual algorithms for non-geometric bipartite matching
and minimum-cost flow.
This pattern is not new, see for example \note{TODO}.
Unlike these previous works, we focus on obtaining running time dependencies on
$k$ or $r$ instead of $n$, that is, faster for inputs with small $r$ or $k$.
We begin in Section~\ref{section:prelim} by introducing notation for matching
and minimum-cost flow.

% O((n + k^2)\polylog n)

First in Section~\ref{section:hung}, we show that the Hungarian algorithm~\cite{Kuhn55}
combined with a BCP oracle solves geometric partial matching exactly in time
$O((n + k^2)\polylog n)$.
Mainly, we show that we can separate the $O(n\polylog n)$ preprocessing time
for building the BCP data structure from the augmenting paths' search time,
and update duals in a lazy fashion such that the number of dual updates per
augmenting path is $O(k)$.

\begin{theorem}
\label{theorem:hung}
Let $A$ and $B$ be two point sets in the plane with $|A| = r$ and $|B| = n$ satisfying $r \le n$, and let $k$ be a
parameter.  A minimum-cost geometric partial matching of size $k$
can be computed between $A$ and $B$ in $O((n + k^2)\polylog n)$ time.
\end{theorem}

% O((n + k\sqrt{k})\polylog(n)\log(n/\eps))

Next in Section~\ref{section:goldberg}, we apply a similar technique to the unit-capacity min-cost circulation
algorithm of Goldberg, Hed, Kaplan, and Tarjan~\cite{GHKT17}.
The resulting algorithm finds a $(1 + \eps)$-approximation to the optimal
geometric partial matching in $O((n + k\sqrt{k})\polylog n \log(n/\eps))$
time.

\begin{theorem}
\label{theorem:gmcm}
Let $A$ and $B$ be two point sets in the plane with $|A| = r$ and $|B| = n$ satisfying $r \le n$, and let $k$ be a
parameter.
A $(1+\eps)$ geometric partial matching of size $k$
can be computed between $A$ and $B$ in
$O((n + k\sqrt{k})\polylog n \log(n/\eps))$ time.
\end{theorem}

% add the ~O(rn^{3/2}) version

Our third algorithm solves the transportation problem in the unbalanced
setting.
%with $|A| = r$ and $|B| = n$.
This time, we use the strongly polynomial uncapacitated min-cost flow algorithm
by Orlin~\cite{xxx} \note{Cite}.
The result is an $O(n^{3/2} r \polylog n)$ time algorithm for unbalanced
transportation.
This improves over the $O(n^2 \polylog(n))$ time algorithm of %TODO cite
when $r = o(\sqrt{n})$.

\begin{theorem}
\label{theorem:orlin}
Let $A$ and $B$ be two point sets in the plane with $|A| = r$ and $|B| = n$ satisfying $r \le n$, with
supplies and demands given by the function $\tsupply(\cdot)$ \note{from $A\cup B$ to $\mathbb{Z}$?} such that
$\sum_{a \in A} \tsupply(a) = \sum_{b \in B} \tsupply(b)$.
An optimal transportation map can be computed in $O(n^{3/2}r\polylog n)$ time.
\end{theorem}

%TODO STILL IN PROGRESS, WE DON'T HAVE A SOLUTION YET. REMOVE IF FAILS.

%Finally, we show that an algorithm by Orlin~\cite{} for uncapacitated min-cost
%flow can be modified to give an $O(nr\polylog(n))$ time algorithm for the
%unbalanced transportation problem.
%Unlike matching, vertices may be ``matched'' (transporting) to more than one
%other vertex.
%As a result, it seems possible that the search procedure reaches vertices which
%do not contribute to a new augmenting path or towards finding unreached $B$
%vertices, forcing the search to backtrack.
%Avoiding the backtracking is the main challenge for this algorithm.
%% how?

By nature of the BCP/NN oracles we use, our results generalize to any $L_p$ distances. \note{Mention Euclidean distance earlier.}


\section{Preliminaries}
\label{section:prelim}

\subsection{Matching}

Let $G$ be a bipartite graph between vertex sets $A$ and $B$ and edge set $E$,
with costs $c(v, w)$ for each edge $e$ in $E$.
We use $C := \max_{e \in E} c(e)$, and assume that the problem is scaled such
that $\min_{e \in E} c(e) = 1$.
A \emph{matching} $M \subseteq E$ is a set of edges where no two edges share an
endpoint.
We use $V(M)$ to denote the vertices matched by $M$.
The \emph{size} of a matching is the number of edges in the set, and the
\emph{cost} of a matching is the sum of costs of its edges.
The \emph{minimum-cost partial matching problem (MPM)} asks to find a size $k$
matching $M^*$ of minimum cost.

\subsection{Minimum-cost flow}

\note{Collect definitions into paragraphs.}

\paragraph{Network.}
For minimum-cost flow, let $G_0 = (V, E_0)$ be a directed graph with
nonnegative arc capacities $u(v, w)$ and costs $c(v, w)$ for each arc
$(v, w) \in E_0$.
We say $G_0$ is \emph{unit-capacity} if $u(v, w) = 1$ holds for all arc $(v, w)$.
Let $\fsupply: V \to \ints_{\geq 0}$ be a supply-demand function on $V$, satisfying $\sum_{v \in V} \fsupply(v) = 0$.
The positive values of $\fsupply(v)$ are referred to as \emph{supply}, and the negative values of $\fsupply(v)$ as \emph{demand}.

We augment $G_0$ to make it \emph{symmetric}
%for every arc $(v, w) \in E_0$ its reverse $(w, v)$ is also an arc;
and the costs
\emph{antisymmetric}
%$c(v, w) = -c(w, v)$).
by creating an arc $(w, v)$ for each $(v, w) \in E_0$ and define $u(w, v) = 0$ and $c(w, v) = -c(v, w)$.
Denote this set of new \emph{reverse arcs} by $E^R$.
\note{How do you feel about using darts and arcs to describe the distinction?}
From here forward, we work with the symmetric multigraph
$G = (V, E = E_0 \cup E^R)$. \note{Oh man.  This is a mouthful, use English.}
A \emph{network} $(G, c, u, \fsupply)$ is a graph $G$ augmented with arc costs, capacities, and a supply-demand function on vertices of $G$.

\paragraph{Pseudoflows.}
A \emph{pseudoflow} $f$ is an antisymmetric function on arcs \note{define codomain; integers?}
satisfying $f(v, w) \leq u(v, w)$ for all arcs $(v, w)$.
We say that $f$ \emph{saturates} an arc $e$ if $f(v, w) = u(v, w)$.
All our algorithms will handle integer-valued pseudoflows, so in the
unit-capacity setting an arc is either saturated or has zero flow.
Given a pseudoflow $f$, we define the \emph{imbalance} of a vertex to be
\[
e_f(v) \coloneqq \fsupply(v) + \sum_{(w, v) \in E}{f(w, v)} - \sum_{(v, w) \in E}{f(v, w)}.
\]
We call positive imbalance \emph{excess} and negative imbalance \emph{deficit}; and
vertices with positive and negative imbalance \emph{excess vertices} and \emph{deficit vertices}, respectively.
A vertex is \emph{balanced} if it has zero imbalance.
If all vertices are balanced, the pseudoflow is a \emph{circulation}.
The cost of a pseudoflow is
\[
\cost(f) \coloneqq \sum_{(v, w) \in E} c(v, w) \cdot f(v, w).
\]
The \emph{minimum-cost flow problem (MCF)} asks to find the circulation $f^*$ of
minimum cost.

\paragraph{Residual network.}
For each arc $(v, w)$, the \emph{residual capacity} with respect to
pseudoflow $f$ is defined to be $u_f(v, w) \coloneqq u(v, w) - f(v, w)$.
The set of \emph{residual edges} \note{arcs?} is defined as
\[
E_f \coloneqq \{(v, w) \in E \mid u_f(v, w) > 0\}.
\]
We call $G_f = (V, E_f)$ the \emph{residual graph} with respect to pseudoflow $f$.
A pseudoflow $f'$ in $G_f$ can be ``added'' or ``augmented'' to $f$ to produce
a new pseudoflow (that is, the arc-wise addition $f + f'$ is a valid pseudoflow
in $G$).
A pseudoflow $f'$ in $G_f$ is an \emph{improving flow} if
\begin{enumerate}[(1)]\itemsep=0pt
\item
$0 \leq e_{f'}(v) \leq e_f(v)$ for all excess vertices $v$,
\item
$0 \leq -e_{f'}(v) \leq -e_f(v)$ for all deficit vertices $v$, and
%\item
% if $e_f(v) = 0$ then $e_{f'}(v) = 0$, \note{this follows from (1) or (2)} and
\item $\sum_{v \in V} |e_{f'}(v)| < \sum_{v \in V} |e_f(v)|$ holds. \note{this follows from (1) and (2) too?}
\end{enumerate}
If improving flow $f'$ is on a simple path (from an excess vertex to a deficit
vertex), we call it an \emph{augmenting-path flow} \note{path flow for short? only used twice throughout the paper} and its underlying support path \note{support undefined} an
\emph{augmenting path}.
If $f'$ saturates at least one residual arc in every augmenting path in $G_f$,
we call $f'$ a \emph{blocking flow}.
In other words, for blocking flow $f'$, there is no augmenting-path flow
$f''$ in $G_f$ for which $f + (f' + f'')$ is a feasible pseudoflow in $G$.

\subsection{Primal-dual augmentation algorithms}

The Hungarian algorithm begins with an empty matching and gradually increases its size to $k$ using \emph{alternating augmenting paths}.
Given a non-maximal matching $M$, an alternating augmenting path $P$ is a path
between an unmatched vertex $a \in A$ and unmatched $b \in B$.
\note{What is $A$ and $B$? Remind the readers about the bipartite graph again.}
Then, $M' = M \oplus P$ is a matching of size 1 greater.
\note{$\oplus$ undefined.  Personally I believe it's easier to define in words; using notation is fine too.}
By restricting alternating augmenting paths to edges \note{when do you use edges and when do you use arcs?}
which satisfy a certain
cost condition (admissibility, defined momentarily) \note{define it or don't say it}, one can prove that each
intermediate matching of size $j \leq k$ is of minimum-cost among matchings of size $j$.

There is a similar augmentation procedure for flows, which sends improving
flows (e.g. augmenting-path flows) \note{no reason to give out details that does not help with sketch of ideas} to gradually reduce the imbalance in a
pseudoflow to 0, making it a circulation. \note{imbalance of a pseudoflow is undefined; you only define it on the vertices.}
By restricting augmentations to residual arcs satisfying a certain cost
condition (admissibility), one can prove that the resulting circulation is
minimum cost.

\note{The above paragraph might be clearer if you put it after the definition of admissibility; because you can actually provide a formal proof.  Sketch of ideas are not that useful because for experts they don't need to read it, for beginners they won't understand without former definitions.}

\paragraph{LP-duality and admissability.}
Formally, the
\emph{potentials} $\pi(v)$ are the variables of the linear program dual to \note{which primal problem? State the correspodning linear problems explicitly}.
The \emph{reduced cost} of an arc $(v, w)$ in $E_f$ with respect to $\pi$ is
\[
c_\pi(v, w) := c(v, w) - \pi(v) + \pi(w).
\]
\note{Mention that reduced costs are still antisymmetric.}
The \emph{dual feasibility constraint} is that $c_\pi(v, w) \geq 0$ holds for all
residual arcs \note{naturally, not the reverse arcs; thus the distinction between arcs and darts}; potentials which satisfy this constraint are said to be \emph{feasible}.
The linear programming \emph{optimality conditions} state that, for an optimal
circulation $f^*$, there are feasible potentials $\pi^*$ which satisfy
$c_\pi(v, w) = 0$ \note{$\pi^*$?} on all arcs with $f^*(v, w) > 0$.
We can similarly define potentials and reduced costs for matchings, using
$c_\pi(a, b) = c(a, b) - \pi(a) + \pi(b)$ for $(a, b) \in A \times B$. \note{How about the reverse arcs?}

Suppose we relax the dual feasibility constraint to allow for a violation of
$\eps > 0$.
We say that a pseudoflow $f$ is \emph{$\eps$-optimal} \note{with respect to $\pi$} if
$c_\pi(v, w) \geq -\eps$ for all arcs $(v, w)$ in $E_f$ with $u_f(v, w) > 0$.
Note that 0-optimality coincides with the optimality conditions. \note{Careful here.  Technically it's dual feasibility.}
We say that a residual arc $(v ,w)$ satisfying $c_\pi(v, w) \leq 0$ is \emph{admissible}.
We say that an improving flow $f'$ is \emph{admissible} if $f'(v, w) > 0$
only on admissible arcs $(v, w)$.

For matchings, we say that matching $M$ is $\eps$-optimal if $c_\pi(a, b) \leq \eps$ for
$(a, b) \in M$ and $c_\pi(a, b) \geq -\eps$ $(a, b) \in E \setminus M$.
Matching edges (resp.\ nonmatching edges) are \emph{admissible} if $c_\pi(a, b) \geq 0$ (resp.\ $c_\pi(a, b) \leq 0$); and an alternating augmenting path is \emph{admissible}
if all its edges are.
For both matching and flows, 0-optimal $f$ implies the admissibility condition
is with equality, instead ($c_\pi(v, w) = 0$).

\note{I got the sense that it might be helpful to define admissibility at the start of the flow section and the matching section separately.}

%Now, we can concretely state how admissible augmentations lead to a correct algorithm for $\eps > 0$.
\begin{lemma}
	Let $f$ be an $\eps$-optimal pseudoflow in $G$ and let $f'$ be an
	admissible improving flow in $G_f$.
	Then $f + f'$ is also $\eps$-optimal.
\end{lemma}
\begin{proof}
	Augmentation by $f'$ will not change the potentials, but may introduce
	new arcs with $u_{f+f'}(v, w) > 0$.
	We will verify that these arcs satisfy the $\eps$-optimality condition.
	Such an arc $(v, w)$ must have $u(v, w) = f(v, w) > (f+f')(v, w)$,
	implying $f'(w, v) > 0$.
\note{I don't understand.  Never write a sentense that requires multiple steps to decode. I think what you meant is $u_f = 0$ thus $u=f$, and $u_{f+f'} > 0$ thus $u-(f+f') > 0$; finally $f'(v,w) > 0$ thus $f'(w,v) < 0$.}
	By assumption that $f'$ is admissible, $(w, v)$ was an admissible arc, thus
	$c_\pi(w, v) \leq 0$, implying $c_\pi(v, w) \geq 0$.
	Thus, all such arcs have $c_\pi(v, w) \geq 0 \geq -\eps$, and $f + f'$
	is $\eps$-optimal.
\end{proof}

With a similar argument, we could prove the same for matchings. \note{Proof it or cite it, at least in full version.}
Finally, we show that $\eps$-optimality is sufficient to certify that a
circulation is an approximate MCF solution, when the underlying graph is
of unit-capacity.

\begin{lemma}
\label{lemma:mcf_cost}
Let $G$ be a unit-capacity graph with $n$ vertices and $m$ arcs, let $f$ be an
$\eps$-optimal circulation in $G$, and let $f^*$ be an optimal circulation for
$G$.
Then, $\cost(f) \leq \cost(f^*) + m\eps$.
\end{lemma}

\note{AX: this may be the wrong cost analysis for approximation. would like a
stronger statement that addresses 0 cost edges (for instance)}
\begin{proof}
By the flow decomposition theorem \note{cite?}, there is a residual pseudoflow
$f'$ such that $f + f' = f^*$, and $f'$ can be decomposed into a set of unit
flows on edge-disjoint cycles in $G_f$.
The number of edges used by these cycles is at most $m$.
The cost of a residual cycle is equal to its reduced cost, since the potentials
telescope, so the cost of each $f'$ cycle $\Gamma$ is at least $-|\Gamma|\eps$
by $\eps$-optimality of $f$.
Thus, $\cost(f') \geq -m\eps$ , and therefore 
$\cost(f) \leq \cost(f^*) + m\eps$.
\end{proof}

This bound can be improved if we have a better upper bound on the number of
edges used in the cycles of $f'$.
Indeed, the algorithm in Section~\ref{section:goldberg} gives a
bound of $6k$, and converts the statement from an additive approximation to a
relative approximation. \note{Maybe not here; move to Sec.\ 4.}
Since our matching algorithm uses a 0-optimal (exact) solution, we do not
include a proof for approximation quality of $\eps$-optimal matchings. \note{Which means you don't have to explain.}


\section{Matching with the Hungarian algorithm}
\label{section:hung}

The Hungarian algorithm maintains a 0-optimal (initially empty) matching $M$,
and repeatedly augments by alternating augmenting paths of admissible edges
until $|M| = k$.
To this end, the algorithm maintains a set of feasible potentials $\pi$ and
updates them to find augmenting paths of admissible edges. \note{admissible augmenting path?}
It maintains the invariant that matching edges are admissible.
Since there are $k$ augmentations and each alternating path has length at most
$2k-1$, the total time spent on bookkeeping the matching is $O(k^2)$.
This leaves the analysis of the subroutine that updates the potentials and
finds an admissible augmenting path; we call this subrouotine the \emph{Hungarian search}.

\begin{figure*}
\centering
\begin{minipage}{.7\linewidth}
\begin{algorithm}[H]
\caption{Hungarian algorithm}
\begin{algorithmic}[1]
\Function{Match}{$G = (A \cup B, E)$, $k$}
	\State $M \gets \emptyset$
	\State $\pi(v) \gets 0$ for all $v \in A \cup B$
	\While{$|M| < k$}
		\State $\Pi \gets$ \Call{Hungarian-Search}{$G$, $M$, $\pi$}
		\State $M \gets M \oplus \Pi$
	\EndWhile \note{indentation is enough for scope}
	\State\Return $M$
\EndFunction
\end{algorithmic}
\end{algorithm}
\end{minipage}
\end{figure*}


\begin{theorem}[Time for Hungarian algorithm]
\label{theorem:hung_orig}
Let $G = (A \cup B, A \times B)$ be an instance of geometric partial matching
with $|A| = r \geq |B| = n$, and parameter $k \leq r$.
Suppose the Hungarian search finds each augmenting path in $T(n, k)$ time after
a one-time $P(n, k)$ preprocessing time.
Then, the Hungarian algorithm finds the optimal size $k$ matching in time
$O(P(n, k) + k T(n, k) + k^2)$.
\end{theorem}

\subsection{Hungarian search}

Let $S$ be the set of vertices that can be reached from an unmatched $a \in A$
by admissible residual edges, initially the unmatched vertices of $A$.
The Hungarian search updates potentials in a Dijkstra's algorithm-like manner,
expanding $S$ until it includes an unmatched $b \in B$ (and thus an admissible
alternating augmenting path).
The ``search frontier'' of the Hungarian search is
$(S \cap A) \times (B \setminus S)$.
From the frontier, we \emph{relax} the edge with minimum reduced cost, changing
the duals such that the edge becomes admissible, and adding the opposite $B$
vertex into $S$.

The dual update uniformly decreases the reduced costs of the frontier edges.
Since $(a', b')$ is the minimum reduced cost frontier edge, the potential
update in line~\ref{line:hs_update} does not make any reduced cost negative,
and thus preserves the dual feasibility constraint for all edges.
The algorithm is shown below as Algorithm~\ref{algorithm:hung_hs}.

\begin{figure*}
\centering
\begin{minipage}{.8\linewidth}
\begin{algorithm}[H]
\caption{Hungarian Search (matching)}
\label{algorithm:hung_hs}
\begin{algorithmic}[1]
\Require{$c_\pi(a, b) = 0$ for all $(a, b) \in M$}
%\Statex %newline
\Function{Hungarian-Search}{$G = (A \cup B, E)$, $M$, $\pi$}
	\State $S \gets a \in (A \setminus V(M))$
	\Repeat
		\State $(a', b') \gets \argmin\{c_\pi(a, b) \mid (a, b) \in (S \cap A) \times (B \setminus S)\}$
		% \State $\gamma \gets c_\pi(a', b')$ \note{$\gamma$ is never used afterwards}
		\State $\pi(v) \gets \pi(v) + c_\pi(a', b'), \forall v \in S$
			\Comment{make $(a', b')$ admissible}
			\label{line:hs_update}
		\State $S \gets S \cup \{b'\}$
		% \Statex %newline
		\If{$b' \not\in V(M)$} \Comment{$b'$ unmatched}
			\State $\Pi \gets$ alternating augmenting path from $S$ to $b'$
			\State\Return $\Pi$
		\Else \Comment{$b'$ is matched to some $a'' \in A \cap V(M)$}
			\State $S \gets S \cup \{a''\}$
		\EndIf
	\Until{$S = A \cup B$}
	\State\Return failure
\EndFunction
\end{algorithmic}
\end{algorithm}
\end{minipage}
\end{figure*}

By tracking the forest of relaxed edges (e.g. back pointers), it is
straightforward to recover the alternating augmenting path $\Pi$ once we reach
an unmatched $b' \in B$.
We make the following observation about the Hungarian search:

\begin{lemma}
\label{lemma:hungsearch_length}
There are at most $k$ edge relaxations before the Hungarian search finds an
alternating augmenting path.
\end{lemma}

\begin{proof}
Each edge relaxation either leads to a matched vertex in $B$ (there are at most
$k-1$ such vertices), or finds an unmatched vertex and ends the search.
\end{proof}

In general graphs, the minimum edge is typically found by pushing all
encountered $(S \cap A) \times (B \setminus S)$ edges into a priority queue.
However, in the bipartite complete graph, this may take $\Theta(rn\polylog(n))$
time for each Hungarian search --- edges are being pushed into the queue even when
they are not relaxed.
We avoid this problem by finding an  edge with minimum cost using \emph{bichromatic
closest pair} (BCP) queries on an additively weighted Euclidean distances,
for which there exist fast %(poly-logarithmic query and update)
dynamic data structures.
Given two point sets
$P$ and $Q$ in the plane,
the task for BCP problem is to find two points $p \in P$ and $q \in Q$ minimizing the (adjusted) distance
$\|p - q\| - \omega(p) + \omega(q)$, for some real-valued vertex weights
$\omega(p)$.
In our setting, the vertex weights will be set as the potentials; the corresponding adjusted distance then will be the reduced costs.

\note{Short history on BCP?}
The state of the art dynamic BCP data structure from Kaplan, Mulzer,
Roditty, Seiferth, and Sharir~\cite{KMRSS17} supports point insertions and deletions in
$O(\polylog(n))$ time, and answers queries in $O(\log^2 n)$ time.
The following lemma, combined with Theorem~\ref{theorem:hung_orig}, completes
the proof of Theorem~\ref{theorem:hung}.

\begin{lemma}
\label{lemma:hs_time}
Using the dynamic BCP data structure from Kaplan \etal, we can implement
Hungarian search with $T(n, k) = O(k\polylog(n))$ and 
$P(n, k) = O(n\polylog(n))$.
\end{lemma}

\begin{proof}
We will maintain a BCP \note{BCP is a \emph{problem}, not a \emph{data structure}} between $P = (S \cap A)$ and
$Q = (B \setminus S)$.
Changes to the BCP sets \note{undefined} are entirely driven by changing $S$; that is, updates to $S$ incur BCP insertions/deletions.
We first analyze the bookkeeping besides the dual updates, and then
show how dual updates can be implemented efficiently.

\begin{enumerate}
\item Let $S^t_0$ \note{Is there a reason why you want the subscript?  Do you ever define $S^t$?} denote the initial set $S$ at the beginning of the
	$t$-th Hungarian search, that is, the set of unmatched points in $A$
	after $t$ augmentations.
	At the very beginning of the Hungarian algorithm, we initialize
	$S^0_0 \gets A$ (meaning that $P = A$ and $Q = B$), which is a
	one-time insertion of $O(n)$ points into BCP.
	On each successive Hungarian search, $S^t_0$ shrinks as more
	and more points in $A$ are matched.
	Assume for now that, at the beginning of the $(t+1)$-th
	Hungarian search, we are able to construct $S^t_0$ from the
	previous iteration.
	To construct $S^{t+1}_0$, we simply remove the $A$ point \note{point in $A$} that
	was matched by the $t$-th augmenting path.
	Thus, with that assumption, we are able to initialize $S$ using
	one BCP deletion operation per augmentation.

\item During each Hungarian search, points are added to $P$ (that is, some points in $A$ are
	added to $S$) and removed from $Q$ (points in $B$ added to $S$), which will happen at most once per edge relaxation.
	By Lemma~\ref{lemma:hungsearch_length} the number of relaxed
	edges is at most $k$, so the number of such BCP operations is
	also at most $k$.

\item To obtain $S^t_0$, we keep track \note{give a name to such points} of the
	points added since $S^t_0$ in the last Hungarian search
	(i.e.\ those of (2)). \note{Unclear}
	After the augmentation, we use this log \note{use the name} to delete the added
	vertices from $S$ and recover $S^t_0$.
	By the argument in (2) there are $O(k)$ of such points to
	delete, so reconstructing $S^t_0$ takes $O(k)$ BCP operations.
	\note{TODO instead of reversing a log, is persistence an easier solution to this?}
\end{enumerate}

We spend $P(n, k) = O(n \polylog(n))$ time to build
the initial BCP.
The number of BCP operations associated with each Hungarian search is
$O(k)$, so the time spent on BCP operations in each Hungarian search
is $O(k \polylog(n))$.

As for the potential updates,
we modify a trick from Vaidya~\cite{Vaidya89} to batch potential
updates such that the dual updates we do perform can be charged to a
BCP insertion or deletion. \note{Mouthful}
Throughout the course of the Hungarian algorithm, we maintain a value
$\delta$ (initially 0) which aggregates the dual changes.
Vertices that are added to $S$ are saved into $P$ \note{I don't understand; do you mean only when vertices in $A$ are added to $S$?} with weight
$\omega(p) \gets \pi(p) - \delta$.
When the points of $S$ have their duals \note{Undefined. You mean their potentials?} increased in (2), we instead
raise $\delta \gets \delta + c_\pi(\hat{a}, \hat{b})$. \note{What is $\hat{a}$ and $\hat{b}$?}
Thus, the ``true'' potential for any point in $S$ is
$\omega(p) + \delta$.
For points outside $S$ (i.e. $B \setminus S$) \note{only point in $B$?}, we simply use the true
potential as the BCP weight.
Since all $S \cap A$ BCP weights \note{you mean BCP weights of points in $P$?} are uniformly offsetted by $\delta$, the solution returned by the BCP oracle does not change.
Once a point is removed from $S$, we update its true potential
to be $\pi(p) \gets \omega(p) + \delta$.

Obviously \note{Never use this word}, the number of updates to $\delta$ is equal to the number of
edge relaxations, which is $O(k)$ per Hungarian search.
The number of times we have to compute the true potential is bounded by
the number times we remove a point from $S$, which is at most $O(k)$ per Hungarian search as well.
The total time spent on potential updates per Hungarian search is therefore
$O(k)$.
Overall, the time spent per Hungarian search is $T(n, k) = O(k\polylog(n))$.

\note{The proof gets more handwavy as the paragraph progresses.  Consider a revision after this round.}
\end{proof}


\section{Matching with the Goldberg~{\etal} algorithm}
\label{section:goldberg}

The basis of the algorithm in this section is a \emph{cost-scaling} algorithm
for unit-capacity min-cost flow from \cite{GHKT17}.
Before describing the algorithm, we first give a linear-time reduction from
min-cost matching to unit-capacity min-cost flow, which allows us to apply the
Goldberg~{\etal} algorithm to partial matching.

\subsection{MPM to unit-capacity MCF reduction}
\label{subsection:mcm_mcf_reduction}

For a partial matching problem on $G = (A \cup B, E_0)$ with parameter $k$, we
direct the bipartite edges of $E_0$ from $(A \to B)$, with costs equal to the
original cost $c(a, b)$ and capacity 1.
Next, we add a dummy vertex $s$ with arcs $(s, a)$ to every $a \in A$,
and respectively a dummy vertex $t$ with arcs $(b, t)$ for each $b \in B$,
all with arc cost 0 and capacity 1.
For each of the above arcs $(v, w)$, we also add a reverse arc $(w, v)$ with
cost $c(w, v) = -c(v, w)$ and capacity 0. \note{is this consistent with the other residual graph description?}
Let the complete set of arcs be $E$, and $V = A \cup B \cup \{s, t\}$.
Set $\fsupply(s) = k$, $\fsupply(t) = -k$, and $\fsupply(v) = 0$ for all other
vertices.
Let the resulting graph be $H = (V, E)$.

\begin{observation}
\label{observation:dag}
	The arcs of $H$ with positive capacity form a directed acyclic graph.
\end{observation}

In other words, there will be no cycles of positive flow in circulations on
$H$.
With this, we can show that the number of arcs used by any integer pseudoflow
in $H$ (with $O(k)$ excess) is $O(k)$.

\begin{lemma}
\label{lemma:reduction_count}
Let $f$ be an integer pseudoflow in $H$ with $O(k)$ excess, and let
$E_{>0}(f) = \{(v, w) \mid f(v, w) > 0\}$.
Then, $|E_{>0}(f)| = O(k)$.
\end{lemma}

\begin{proof}
By Observation~\ref{observation:dag}, the positive-flow edges of $f$ do not
contain a cycle.
Thus, the flow decomposition of $f$ is a series of paths, each of which can
create a single unit of excess if it does not terminate at $t$.
By assumption, then, there are $O(k)$ such paths.
The maximum length of any path of positive-flow arcs in $H$ is 3, by the
capacities in the construction.
We conclude that the number of positive flow arcs in $f$ is $O(k)$.
\end{proof}

It is straightforward to show that any integer circulation on $H$ uses exactly
$k$ of the $(A \to B)$ arcs, which correspond to the edges of a size $k$
matching.
For a circulation $f$ in $H$, we use $M_f \subseteq E$ to denote the
corresponding matching.
Observe that $\cost(f) = \cost(M_f)$, so an $\alpha$-approximation to the MCF
problem on $H$ is an $\alpha$-approximation to the matching problem on $G$.

For cost approximation, we can improve Lemma~\ref{lemma:mcf_cost} on $H$.
Note that for integer-valued (e.g. unit) capacities, there is always an
integer-valued optimal circulation.
\begin{lemma}
\label{lemma:goldberg_cost_add}
Let $f$ an $\eps$-optimal integer circulation in $H$, and $f^*$ an optimal
integer circulation for $H$.
Then, $\cost(f) \leq \cost(f^*) + 6k\eps$.
\end{lemma}

\begin{proof}
We label the arcs of $H_f$ as follows: \emph{forward arcs} directed from
$s \to A$ or $A \to B$ or $B \to t$, and \emph{reverse arcs} in the opposite
directions.
Observe that a residual cycle $\Gamma$ must have exactly half of its edges be
reverse arcs.
The reverse arcs may either be (i) on one of the $M_f$ edges or else (ii)
between $\{s\} \times A$ or (iii) between $B \times \{t\}$.
If it is of type (ii) or (iii), there is an adjacent type (i) reverse arc.
Thus, we can charge the reverse arcs of $\Gamma$ to $M_f \cap \Gamma$ edges
with at most 3 charge per edge of $M_f \cap \Gamma$.
We can then charge all arcs of $f' = (f^* - f) = \sum \Gamma_i$ to $M_f$ with
at most 6 charge per $M_f$ edge.
As $|M_f| = k$, the number of arcs in $f'$ is at most $6k$.
The rest of the argument proceeds as in Lemma~\ref{lemma:mcf_cost}.
\end{proof}

Suppose we scaled arc costs (via uniform scaling of the input points) such that
the minimum cost (closest pair distance) is 1.
Then, $\cost(f^*) \geq k$, and we can turn Lemma~\ref{lemma:goldberg_cost_add}
into a relative approximation.

\begin{corollary}
\label{corollary:flow_approx}
Let $f$ an $\eps$-optimal integer circulation in $H$, and $f^*$ an optimal
integer circulation for $H$.
Suppose costs are scaled such that $\min \|a - b\| = 1$.
Then, $\cost(f) \leq (1 + 6\eps) \cost(f^*)$.
\end{corollary}

\begin{corollary}
\label{corollary:match_approx}
Let $f$ an $(\eps'/6)$-optimal integer circulation in $H$, and $M^*$ an optimal
size $k$ matching of $G$.
Suppose costs are scaled such that $\min \|a - b\| = 1$.
Then, $\cost(M_f) \leq (1 + \eps') \cost(M^*)$.
\end{corollary}

In other words, a $(\eps'/6)$-optimal circulation is sufficient for a
$(1 + \eps')$-approximate matching.

\subsection{Algorithm description}

The Goldberg~{\etal}~\cite{GHKT17} algorithm is based on \emph{cost-scaling} or
\emph{successive approximation}, originally due to Goldberg and
Tarjan~\cite{GT90}.
The algorithm finds $\eps$-optimal circulations for geometrically shrinking
values of $\eps$.
Each period where $\eps$ holds constant is called a \emph{scale}.
Once $\eps$ is sufficiently small, the $\eps$-optimal flow is a suitable
approximation or even optimal when costs are integer~\cite{GT90,GHKT17}.
We present this algorithm as an approximation is because costs in geometric
partial matching (i.e. Euclidean distances) are generally not integer.

\begin{algorithm}
\caption{Cost-Scaling MCF}
\begin{algorithmic}[1]
\Function{MCF}{$H$, $\eps'$}
	\State $\eps \gets kC$
	\State $f \gets 0$
	\State $\pi \gets 0$
	\Repeat
		\State $(f, \pi) \gets$ \Call{Scale-Init}{$H$, $f$, $\pi$}
		\State $(f, \pi) \gets$ \Call{Refine}{$H$, $f$, $\pi$}
		\State $\eps \gets \eps/2$
	\Until{$\eps \leq \eps'/6$}
	\State\Return $f$
\EndFunction
\end{algorithmic}
\end{algorithm}

Note that the 0 flow is trivially $kC$-optimal for $H$.
At the beginning of each scale, \textsc{Scale-Init} takes the previous
circulation (now $2\eps$-optimal) and transforms it into an $\eps$-optimal
pseudoflow with $O(k)$ excess.
The rest of the scale, in \textsc{Refine}, reduces the excess in this
pseudoflow to 0, making an $\eps$-optimal circulation.
The bulk of this section will describe and analyze \textsc{Scale-Init} and
\textsc{Refine}.

For now, we analyze the number of scales (iterations of the outer loop).
Initially $\eps = kC$, and the algorithm is stopped once $\eps \leq \eps'/6$.
Thus, the number of scales is $O(\log(kC/\eps'))$.
For geometric matching problems, there is a simple way to preprocess the point 
set such that $C = O(n^2)$, effectively, by Sharathkumar and Agarwal~\cite{SA12}.
Using this preprocessing gives us $O(\log(n/\eps'))$ scales, instead.
We briefly describe this preprocessing procedure at the end of this section.

\begin{lemma}
\label{lemma:goldberg_scales}
The cost-scaling algorithm finds a $(1 + \eps')$-approximate matching after
$O(\log(n/\eps'))$ scales.
\end{lemma}

\subsection{\textsc{Scale-Init}}

\begin{algorithm}
\caption{Scale Initialization}
\label{algorithm:scale_init}
\begin{algorithmic}[1]
\Function{Scale-Init}{$H$, $f$, $\pi$}
	\State $\forall a \in A, \pi(a) \gets \pi(a) + \eps$
	\State $\forall b \in B, \pi(b) \gets \pi(b) + 2\eps$
	\State $\pi(t) \gets \pi(t) + 3\eps$
	\Statex %newline
	\ForAll{$(v, w) \in E_{>0}(f)$}
		\If{$c_\pi(w, v) < -\eps$}
			\State $f(v, w) \gets 0$
		\EndIf
	\EndFor
	\State\Return $(f, \pi)$
\EndFunction
\end{algorithmic}
\end{algorithm}

The procedure is described in Algorithm~\ref{algorithm:scale_init}.
Let the $H_f$ arcs directed from $s \to A$ or $A \to B$ or $B \to t$ be
\emph{forward arcs}, and let those in the opposite directions be
\emph{reverse arcs}.
The first 4 lines of \textsc{Scale-Init} raise the reduced cost of each
forward arc by $\eps$, therefore making all forward arcs $\eps$-optimal.
For example, a forward arc of $A \to B$ now has reduced cost
\begin{equation*}
	c(a, b) - (\pi(a) + \eps) + (\pi(b) + 2\eps)
	= c_\pi(a, b) + \eps
	\geq -2\eps + \eps
	= -\eps.
\end{equation*}
In the lines after, we deal with the reduced cost of reverse arcs by simply
de-saturating them if they violate $\eps$-optimality.
Note that forward arcs will not be de-saturated in this step, since they are
now $\eps$-optimal.

To bound the amount of excess after \textsc{Scale-Init}, we first bound the
number of edges with positive flow.
\begin{lemma}
\label{lemma:support_size_start}
Let $f$ be the flow at the beginning of \textsc{Scale-Init} and
$E_{>0}(f) = \{(v, w) \in E_f \mid f(v, w) > 0\}$.
Then, $|E_{>0}(f)| = 3k$.
\end{lemma}

\begin{proof}
By assumption, $f$ is a circulation sending all the supply at $s$ to $t$. 
Thus, $f$ can be decomposed into flows on $k$ $s$-$t$ paths and 0 flow cycles, 
since $H$ is acylic.
Each $s$-$t$ path has length 3 in $H$, therefore the number of edges in 
$E_{>0}(f)$ is $3k$.
\end{proof}

\begin{lemma}
\label{lemma:scale_init}
In $O(n)$ time, \textsc{Scale-Init} turns a $2\eps$-optimal circulation into an
$\eps$-optimal pseudoflow with $O(k)$ excess.
\end{lemma}

\begin{proof}
The potential updates affect every vertex except $s$, so this takes $O(n)$
time.
As for the arc de-saturations, every reverse arc is induced by positive flow on
a forward arc, and the number of positive flow edges in $f$ is $O(k)$.
The total number of edges that get examined by the loop is therefore $O(k)$.
In total, the time taken is $O(n)$.

For the amount of excess, notice that new excess is only created due to the
de-saturations of reverse arcs.
Because the graph is unit-capacity, each de-saturation creates one unit of
excess.
There are $|E_{>0}(f)| = 3k$ reverse arcs possible, so the total created excess
must be $O(k)$.
\end{proof}

\subsection{\textsc{Refine}}

\textsc{Refine} is implemented using a primal-dual augmentation algorithm,
which sends improving flows on admissible edges like the Hungarian algorithm.
Unlike the Hungarian algorithm, it uses blocking flows instead of augmenting
paths.

\begin{algorithm}
\caption{Refinement}
\begin{algorithmic}[1]
\Function{Refine}{$H = (V, E)$, $f$, $\pi$}
	\While{$\sum_{v \in V} |e_f(v)| > 0$}
		\State $\pi \gets$ \Call{Hungarian-Search2}{$H$, $f$, $\pi$}
		\State $f' \gets$ \Call{DFS}{$H$, $f$, $\pi$}
			\Comment{$f'$ is an admissible blocking flow}
		\State $f \gets f + f'$
	\EndWhile
	\State\Return $(f, \pi)$
\EndFunction
\end{algorithmic}
\end{algorithm}

Using the properties of blocking flows and the unit-capacity input graph,
Goldberg~{\etal} prove that there are $O(\sqrt{k})$ blocking flows before
excess becomes 0.
\note{This is not honest, I think. There is a derivation almost identical to theirs, but they are using a slightly different reduction graph.}

\begin{lemma}[Goldberg~{\etal}~\cite{GHKT17} Lemma 3.11 and Section 6]
Let $f$ be a pseudoflow in $H$ with $O(k)$ excess.
There are $O(\sqrt{k})$ blocking flows before excess is 0.
\end{lemma}

We can combine this with Lemma~\ref{lemma:reduction_count} to argue that the
amount of time spent updating the flow within \textsc{Refine} is
$O(k\sqrt{k})$.

Each step of \textsc{Refine} finds an admissible blocking flow in two stages.
\begin{enumerate}
\item A \emph{Hungarian search}, which updates duals in a Dijkstra-like
	manner until there exists an excess-deficit path of admissible edges.
	There are slight differences from the Hungarian algorithm's ``Hungarian
	search,'' but the final running time is identical.
	We call the procedure \textsc{Hungarian-Search2} to distinguish.

\item A \emph{depth-first search} (\textsc{DFS}) through the set of admissible
	edges to construct an admissible blocking flow.
	It suffices to repeatedly extract admissible augmenting paths until
	no more admissible excess-deficit paths remain.
	By definition, the union of such paths is a blocking flow.
\end{enumerate}
For \textsc{Hungarian-Search2}, we again use a dynamic BCP data structure to
accelerate the Hungarian search after a once-per-\textsc{Refine} preprocessing.
To perform \textsc{DFS} quickly, we can use a dynamic \emph{nearest-neighbor}
(NN) data structure, to discover admissible edges without handling the set of
admissible edges explicitly.
This is applied in a similar way as the BCP is for Hungarian search.

\begin{lemma}
Suppose \textsc{Hungarian-Search2} can be implemented in $T_1(n, k)$ time after
a once-per-\textsc{Refine} $P_1(n, k)$ time preprocessing, and respectively
\textsc{DFS} in $T_2(n, k)$ time after $P_2(n, k)$ preprocessing.
Then, \textsc{Refine} can be implemented in
$O(P_1(n, k) + P_2(n, k) + \sqrt{k}[T_1(n, k) + T_2(n, k)] + k\sqrt{k})$ time.
\end{lemma}

As we will show shortly (Lemmas~\ref{lemma:goldberg_hs_time},
\ref{lemma:goldberg_dfs_time}), the total running time for \textsc{Refine} is 
$O((n + k\sqrt{k})\polylog(n))$.
Combining with Lemmas~\ref{lemma:goldberg_scales} and \ref{lemma:scale_init}
completes the proof of Theorem~\ref{theorem:gmcm}.
At a high level, our analysis strategy is to charge relaxation events in 
the search to arcs of $E_{>0}(f)$.
We first extend Lemma~\ref{lemma:support_size_start} to bound the size of 
$E_{>0}(f)$ throughout \textsc{Refine}.

\begin{lemma}
\label{lemma:support_size_during}
Let $f$ be the integer-valued pseudoflow before or after any iteration of 
\textsc{Refine}, and $E_{>0}(f) = \{(v, w) \in E_f \mid f(v, w) > 0\}$.
Then, $|E_{>0}(f)| = O(k)$.
\end{lemma}

\begin{proof}
From Lemma~\ref{lemma:support_size_start} and the proof of
Lemma~\ref{lemma:scale_init}, \textsc{Refine} begins with a pseudoflow $f$ that
has $|E_{>0}(f)| \leq 3k$.
Each iteration of \textsc{Refine} augments $f$ with an improving flow which
reduces the sum of excess by at least one.
Thus, the total excess in $f$ begins as $O(k)$, and only decreases.

Each unit of excess is either on $s$ (part of the supply) or lies at the end of
a path of $E_{>0}(f)$ edges.
We say an inclusion-maximal path $\Pi \subseteq E_{>0}(f)$ of length at least
one \emph{induces} a unit of excess at its end, and a unit of deficit at its
beginning.
Even if $\Pi$ induces deficit at $v$ and excess at $w$, $v$ may have 
$e_f(v) \geq 0$ and $w$ may have $e_f(v) \leq 0$, i.e. when $v = s$ and $w = t$
respectively.
However, if there are more than $k$ paths inducing deficit at $s$ (resp. 
inducing excess at $t$), then $s$ will be a deficit vertex (resp. $t$ will be 
an excess vertex).
Barring these (up to) $2k$ paths, each inclusion-maximal path $\Pi$ can be
uniquely assigned to a unit of excess and a unit of deficit in $e_f()$.

Let $X$ be the set of inclusion-maximal paths of the edges of $E_{>0}(f)$.
Every edge of $E_{>0}(f)$ is part of some inclusion-maximal path 
(possibly containing only that edge), so $X$ covers $E_{>0}(f)$.
Since $H$ is acyclic, each $\Pi \in X$ has length at most 3, so we have that
$|E_{>0}(f)| \leq 3|X|$.
There is $O(k)$ excess/deficit in $e_f()$ which we can charge to the paths in
$X$ inducing them, as well as at most $2k$ more which induce excess/deficit
that are canceled out by the supply at $s$ or demand at $t$.
It follows that $|X| = O(k)$ and therefore $|E_{>0}(f)| = O(k)$.
\end{proof}


\subsubsection{Hungarian search}

\begin{algorithm}
\caption{Hungarian Search (cost-scaling)}
\begin{algorithmic}[1]
\Function{Hungarian-Search2}{$H = (V, E)$, $f$, $\pi$}
	\State $S \gets \{v \in V \mid e_f(v) > 0\}$
	\Repeat
		\State $\Pi \gets \argmin\{c_\pi(\Pi) \mid \text{$\Pi$ non-empty edge or empty 2-/3-path leaving $S$}\}$
			\label{line:hs_relaxation}
		\State $\gamma \gets c_\pi(\Pi)$
		\If{$\gamma > 0$}
			\Comment{make $\Pi$ admissible if it isn't}
			\State $\pi(v) \gets \pi(v) + \gamma\lceil\frac{\gamma}{\eps}\rceil, \forall v \in S$
		\EndIf
		\State $S \gets S \cup \Pi$
		\Statex %newline
		\State Let $\Pi = v_1, \ldots, v_\ell$
		\If{$e_f(v_\ell) < 0$} \Comment{$\Pi$ reached a deficit}
			\State\Return $(f, \pi)$
		\EndIf
	\Until{$S = (A \cup B)$}
	\State\Return failure
\EndFunction
\end{algorithmic}
\end{algorithm}


\note{a higher level comment about this section, it feels like we need a formal proof of correctness for relaxing empty paths}

Like \textsc{Hungarian-Search}, \textsc{Hungarian-Search2} includes new
vertices into $S$ by relaxing minimum-reduced cost arcs.
Potentials are now raised in intervals of $\eps$, but this still preserves
$\eps$-optimality on the $S \times V \setminus S$ residual arcs.
Similar to the previous discussion, \textsc{Hungarian-Search2} computes the
arcs to relax as the minimum from $O(1)$ candidate categories:
\begin{enumerate}
\item Reverse arcs $(v, w)$ with $(w, v) \in E_{>0}(f)$ using a min-heap.
\item Forward arcs using a BCP data structure between points of $A$ and $B$.
\item Forward arcs from $s$ to $A$ and from $B$ to $t$, using min-heaps.
\item A new category of short (length 2, 3) paths called \emph{empty paths},
	which we describe in the remainder of this section.
\end{enumerate}

We say $v \in A \cup B$ is an \emph{empty vertex} if $e_f(v) = 0$ and no edges
of $E_{>0}(f)$ adjoin $v$.
The analysis from the previous section is unable to charge relaxation steps 
involving empty vertices to $|E_{>0}(f)|$, so the algorithm must deal with them 
separately.
Namely, there is no edge with $f(e) > 0$ adjacent to an empty vertex,
reaching an empty vertex does not terminate the search, and there may be
$\Omega(n)$ empty vertices at once (consider $H_{f = 0}$, the residual graph
of the empty flow).
We use $A_\emptyset$ and $B_\emptyset$ to denote the empty vertices of $A$ and
$B$ respectively.
Vertices that are not empty are called \emph{non-empty vertices}.

For an empty vertex $v$, either residual in-degree ($v \in A_\emptyset$) or
residual out-degree ($v \in B_\emptyset$) is 1.
Instead of querying an empty vertex during the search, we shortcut it using the
length 2 paths to/from non-empty vertices, called \emph{empty 2-paths}.
For example, if $v \in A_\emptyset$ (resp. $v \in B_\emptyset$), then its empty
2-paths have the form $(s, v, b)$ (resp. $(a, v, t)$) for each
$b \in B \setminus B_\emptyset$ (resp. $a \in A \setminus A_\emptyset$).
We say that $(s, v, b)$ is an empty 2-path \emph{surrounding} empty vertex $v$.
Separately, we consider the length 3 $s$-$t$ paths that pass through two empty
vertices, called \emph{empty 3-paths}.
As with 2-paths, we say an empty 3-path $(s, v_1, v_2, t)$ \emph{surrounds}
$v_1 \in A_\emptyset$ and $v_2 \in B_\emptyset$.

Each relaxation step (Line~\ref{line:hs_relaxation} in 
\textsc{Hungarian-Search2}) relaxes either an edge between two non-empty 
vertices (of $S \times V \setminus S$), or an empty 2- or 3-path that starts
in $S$ and ends in $V \setminus S$.
Relaxation steps involving an empty 2- or 3-path will relax the entire path
at once, moving all vertices of the path into $S$.
Relaxation steps that do not involve an empty 2- or 3-path are called
\emph{non-empty relaxations}.

Consider an empty 2-path $(s, v, b)$ that surrounds $v$.
Reduced costs telescope for residual paths, the reduced cost of $(s, v, b)$
does not depend on the potential of $v$.
\begin{equation*}
	c_\pi((s, v, b)) = c_\pi(s, v) + c_\pi(v, b) = c(v, b) - \pi(s) + \pi(b)
\end{equation*}
Thus, we can safely ignore the potential of $v$ until it ceases to be
empty, e.g. after an augmentation across one of its empty paths.
At that point, we can infer $\pi(v)$ from the potentials of the empty 2-path
augmented through (this path must be admissible).
Before we go into the details of updating the sets of empty vertices and their
potentials, we describe the mechanism for querying the minimum-reduced cost
empty 2- and 3-paths.

When the search has $s \in S$, we can query the minimum-reduced cost empty
2-path surrounding $A_\emptyset$ vertices using a data structure
$D_\emptyset(A)$ maintaining
$BCP(P = A_\emptyset, Q = (B \setminus B_\emptyset) \setminus S)$ with weights
$\omega(p) = \pi(s)$ for all $p \in P$, and $\omega(q) = \pi(q)$ for all
$q \in Q$.
It is simple to verify that if $(p, q)$ is the BCP of $P, Q$ above, then its
BCP distance is precisely the reduced cost of the 2-path $(s, p, q)$.
We can build similar query data structures for other empty 2-paths and empty
3-paths, also reporting a pair whose weighted distance is equal to the reduced
cost of the corresponding empty 2- or 3-path.
Empty 2-paths surrounding $B_\emptyset$ vertices can be queried using
$D_\emptyset(B)$ which maintains
$BCP(P = (A \setminus A_\emptyset) \cap S, Q = B_\emptyset)$ with weights
$\omega(p) = \pi(p)$ for all $p \in P$, and $\omega(q) = \pi(t)$ for all
$q \in Q$.
We query $D_\emptyset(B)$ so long as $t \not\in S$.
Lastly, the minimum-reduced cost empty 3-path can be queried using a data
structure $D_\emptyset(A, B)$ maintaining
$BCP(P = A_\emptyset \setminus S, Q = B_\emptyset)$ with weights
$\omega(p) = \pi(s)$ for all $p \in P$, and $\omega(q) = \pi(t)$ for all
$q \in Q$.
We query $D_\emptyset(A, B)$ only while $s \in S$ and $t \not\in S$.

To summarize, each relaxation step of \textsc{Hungarian-Search2} takes the 
minimum between:
\begin{enumerate}
\item Reverse arcs of $E_{>0}(f)$ edges, maintained in a min-heap as their 
	endpoints arrive in $S$.
\item Forward arcs of $(A \setminus A_\emptyset) \cap S \times (B \setminus B_\emptyset) \setminus S$,
	maintained in a BCP data structure with potentials as weights.
\item Forward arcs between $s$ and $(A \setminus A_\emptyset) \cap S$ if
	$s \in S$, maintained in a min-heap.
\item Forward arcs between $(B \setminus B_\emptyset) \cap S$ and $t$ if
	$t \not\in S$, maintained in a min-heap.
\item Empty 2-paths from $s$ to vertices of $(B \setminus B_\emptyset) \setminus S$, if
	$s \in S$, maintained in a BCP data structure $D_\emptyset(A)$.
\item Empty 2-paths from vertices of $(A \setminus A_\emptyset) \cap S$ to $t$, if
	$t \not\in S$, maintained in a BCP data structure $D_\emptyset(B)$.
\item Empty 3-paths, from $s$ to $t$, if $s \in S$ and $t \not\in S$,
	maintained in a BCP data structure $D_\emptyset(A, B)$.
\end{enumerate}
Observe that (1-4) queries all arcs leaving $S$ to non-empty vertices, and 
(5-7) queries the length 2 or 3 paths leaving $S$ through empty vertices.
In other words, any arc leaving $S$ is accounted for in one of these 
structures.
Correctness of \textsc{Hungarian-Search2} follows from the following lemma,
which shows that our special treatment of empty vertices does not change the
way non-empty vertices are added to $S$.

\begin{lemma}
\label{lemma:empty_correct}
%TODO what do we want here? empty paths do not cause non-empty vertices to be added to S out of order.
\note{need a correctness statement here}
\end{lemma}

\begin{proof}
%TODO
\end{proof}

%TODO describe/bound the update process for each data structure:
	% how to find them:
	% empty both: BCP with all empty vertices, using s/t potentials
	%	active as long as s reached, t unreached
	%	updates according to S with deletions
	% empty a: BCP with empty A to nonempty unreached B, using s/b potentials
	%	active as long as s reached
	%	updates according to S with deletions in B
	% empty b: BCP with with nonempty reached A to empty unreached B, using a/t potentials
	%	active as long as t unreached
	%	updates according to S with insertions in A

	% ^ the empty sets will only change through empty relaxations

	% assuming we can find them, how many empty a, b, and both?
	% only one empty both per h.s., starting at s and adding t.
	% empty a leads to a non-empty b, charge to adjoining b support or deficit
	% empty b comes from a non-empty a, charge to adjoining a support or excess

	% how to find empty both? potentials at s, t plus BCP on empty A x empty B
	% how to find empty a? potential at s, min of potentials of nonempty B
	% how to find empty b? potential at t, max of potentials of nonempty A

	% empty/nonempty may only change during augmentation, and only on nodes augmented through
	% charge empty/nonempty d.s. updates to the blocking flow nodes
	% \eps is fixed at the current scale
	% potentials MUST be recovered during augmentation and at scale end
	% seems like fixing them to \pi(s) or \pi(t) is correct; certainly will not violate feas if \pi(s) doesn't


In the next few lemmas, we bound the number of relaxations of each type.
This will provide a time bound for the Hungarian search in terms of the
number of relaxations, each of which incur $O(1)$ BCP or min-heap queries and 
updates.
\note{afterwards, need to provide a time bound of potential updates, or otherwise explain that mechanism}

\begin{lemma}
\label{lemma:goldberg_hs_length1}
There are $O(k)$ non-empty relaxations in \textsc{Hungarian-Search2} before a
deficit vertex is reached.
\end{lemma}

\begin{proof}
Let $E_{>0}(f) = \{(v, w) \in E \mid f(v, w) > 0\}$.
Each edge relaxation adds a new vertex to $S$.
The vertices of $V \setminus S$ fall into several categories:
(i) $s$ or $t$, (ii) $A$ or $B$ vertex with 0 imbalance, and (iii) $A$ or $B$
vertex with deficit ($S$ contains all excess vertices).
The number of vertices in (i) and (iii) is $O(k)$, leaving us to bound the
number of (ii) vertices.

An $A$ or $B$ vertex with 0 imbalance must have an even number of $E_{>0}(f)$
edges.
There is either only one positive-capacity incoming edge (for $A$) or outgoing
edge (for $B$), so this quantity is either 0 or 2.
By the non-emptiness assumption, it must be 2.
We charge 0.5 to each of the two $E_{>0}(f)$ edges; the edges of $E_{>0}(f)$
have no more than 1 charge each.
Thus, the number of (ii) vertex relaxations is $O(|E_{>0}(f)|)$.
By Lemma~\ref{lemma:support_size_during}, $O(|E_{>0}(f)|) = O(k)$.
\end{proof}

\begin{lemma}
\label{lemma:goldberg_hs_length2}
There are $O(k)$ empty 2- and 3-path relaxations in \textsc{Hungarian-Search2}
before a deficit vertex is reached.
\end{lemma}

\begin{proof}
There is only one empty 3-path relaxation, since $t$ can only be added to $S$
once.
This is also the case for the empty 2-paths surrounding a $B_\emptyset$ vertex.

On the other hand, each relaxation of an empty 2-path surrounding an
$A_\emptyset$ vertex adds some non-empty $b \in B \setminus B_\emptyset$ into
$S$.
By definition, $b$ must either have deficit or an adjacent edge of $E_{>0}(f)$.
We charge this relaxation to $b$ if it is deficit, or the adjacent $E_{>0}(f)$
edge otherwise.
No $E_{>0}(f)$ edge is charged more than twice, therefore the total number of
empty 2-path relaxations surrounding $A_\emptyset$ vertices is
$O(|E_{>0}(f)|)$.
By Lemma~\ref{lemma:support_size_during}, $O(|E_{>0}(f)|) = O(k)$.
\end{proof}

\begin{corollary}
\label{corollary:goldberg_hs_length}
There are $O(k)$ relaxations in \textsc{Hungarian-Search2} before a deficit 
vertex is reached.
\end{corollary}

%TODO HERE
In order to prove that \textsc{Hungarian-Search2} can be 

\begin{lemma}
\label{lemma:goldberg_hs_time}
Using a dynamic BCP, we can implement \textsc{Hungarian-Search2} with
$T_1(n, k) = O(k\polylog(n))$ and $P_1(n, k) = O(n\polylog(n))$.
\end{lemma}

\begin{proof}
Like for matchings, we use a BCP to find the argmin quickly; we maintain
$P = (S \cap A)$ and $Q = (B \setminus V)$ using weights
$\omega(v) = \pi(v) - \delta$, and increase $\delta$ in lieu of increasing the
potential of all $S$ vertices.
Using Lemma~\ref{lemma:hs_time} as a basis, we first analyze the number of BCP
operations over the course of \textsc{Hungarian-Search2}.
\begin{enumerate}
\item Let $S^t_0$ denote the initial set $S$ at the beginning of the
	$t$-th Hungarian search, i.e. the set of $v \in V$ with
	$e_f(v) > 0$ after $t$ blocking flows.
	Assume for now that, at the beginning of the $(t+1)$-th
	Hungarian search, we have on hand the $S^t_0$ from the
	previous iteration.
	To construct $S^{t+1}_0$, we remove the vertices that had
	excess decreased to 0 by the $t$-th blocking flow.
	Thus, with that assumption, we are able to initialize $S$ at
	the cost of one BCP deletion per excess vertex, which sums to
	$O(k)$ over the entire course of \textsc{Refine}.
\item During each Hungarian search, a vertex entering $S$ may cause $P$
	or $Q$ to update and incur one BCP insertion/deletion.
	Like before, we can charge these to the number of edge
	relaxations over the course of \textsc{Hungarian-Search2}.
	The number of these is $O(k)$ by 
	Corollary~\ref{corollary:goldberg_hs_length}.
\item Like before, we can meet the assumption in (1) by rewinding a log
	of point additions to $S$, and recover $S^t_0$.
\end{enumerate}

For each of the $O(1)$ data structures that are queried during a relaxation,
the new vertex moved into $S$ as a result of the relaxation causes $O(1)$
insertion/deletion operations.
For each of the data structures mentioned above, insertions and deletions
can be performed in $O(\polylog n)$ time.

For potential updates, we use the same trick as in Lemma~\ref{lemma:hs_time} to
lazily update potentials after vertices leave $S$, but only for non-empty
vertices.
To remind, with lazy updates, the number of potential updates on non-empty
vertices was bounded by the number of relaxations in the Hungarian search,
which is $O(k)$ by Corllary~\ref{corollary:goldberg_hs_length}.

Potentials for the empty vertices must be updated at the end of a scale and 
whenever they stop being empty, i.e. when an augmentation sends flow through 
one of its surrounding empty paths.
In both cases, we fix them to $\pi(a) \gets \pi(s)$ for $a \in A_\emptyset$ and 
$\pi(b) \gets \pi(t)$ for $b \in B_\emptyset$.
This preserves feasibility of the potentials on every empty path, and 
admissibility on the arcs of an empty path that is augmented through.
\note{move correctness of this choice into its own lemma; ``feasible choice''?}
The number of empty vertex potential updates is proportional to the size of 
the blocking flows, which is $O(k\sqrt{k})$ in total for the scale. 
\note{point to a lemma for blocking flow sizes}
\end{proof}

\subsubsection{Depth-first search}

The depth-first search is similar to \textsc{Hungarian-Search2} in that it
uses the relaxation of minimum-reduced cost arcs/empty paths, this time to
identify admissible arcs/empty paths in a depth-first manner.
This requires replacing many of the BCP data structures with nearest-neighbor
(NN) data structures, to query the minimum reduced-cost path leaving a
particular $v' \in S$ rather than all vertices of $S$ simultaneously.

\begin{algorithm}
\caption{Depth-first search}
\begin{algorithmic}[1]
\Function{DFS}{$H = (V, E)$, $f$, $\pi$}
	\State $f' \gets 0$.
	\State $S \gets \{v \in V \mid e_f(v) > 0\}$
	\State $P \gets \emptyset$
	\Repeat
		\State $v' \gets$ \Call{Pop}{$P$}
		\If{$e_f(v') < 0$}
			\Comment{if we reached a deficit, save the path to $f'$}
			\State add to $f'$ a unit flow on the path $P$

			\State $P \gets \emptyset$
		\EndIf

		\Statex %newline
		\State $\Pi \gets \argmin\{c_\pi(\Pi) \mid \text{$\Pi$ non-empty edge or empty 2-/3-path from $v'$ into $V \setminus S$}\}$
		\State $\gamma \gets c_\pi(\Pi)$
		\State Let $\Pi = (v', w_1, \ldots, w_\ell)$

		\Statex %newline
		\If{$\gamma \leq 0$}
			\Comment{if $\Pi$ is admissible, extend the current path}
			\State $S \gets S \cup \Pi$

			\State $P \gets$ \Call{Push}{$P$, $w_\ell$}
		\EndIf

		\If{$e_f(w_\ell) < 0$} \Comment{$w_\ell$ is a deficit}
			\State\Return $(f, \pi)$
		\EndIf
	\Until{$S = \emptyset$}
	\State\Return failure
\EndFunction
\end{algorithmic}
\end{algorithm}

%TODO is this still fine? with the empty path stuff?

\begin{lemma}
\label{lemma:goldberg_dfs_time}
Using a dynamic NN, we can implement \textsc{DFS} with
$T_2(n, k) = O(k\polylog(n))$ and $P_2(n, k) = O(n\polylog(n))$.
\end{lemma}

\begin{proof}
%TODO
\end{proof}








\subsection{Preprocessing for $C = O(n^2)$}

%TODO
\begin{lemma}[Sharathkumar, Agarwal]
	In $O(n\log n)$ time, we can preprocess $A, B$ by partitioning into
	$(A_1, B_1), \ldots, (A_\ell, B_\ell)$ such that
	\begin{enumerate}
	\item each $(A_i, B_i)$ has $|A_i| = |B_i|$,
	\item the union of optimal matching solutions on $(A_i, B_i)$
		is an optimal matching for $A, B$, and
	\item the spread of $(A_i, B_i)$ is $O(n^2)$.
	\end{enumerate}
\end{lemma}






\section{Unbalanced Transportation}

% definitions
% introduce the excess scaling algorithm/Orlin's
% time per hungarian search
% handling problem cases (stars, singletons)


{
\bibliographystyle{abbrv}
\bibliography{ref}
}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
